{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "interested-sculpture",
   "metadata": {
    "papermill": {
     "duration": 0.013887,
     "end_time": "2021-04-26T12:53:54.097098",
     "exception": false,
     "start_time": "2021-04-26T12:53:54.083211",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# SUMMARY\n",
    "\n",
    "This notebook builds on the great pipeline [introduced](https://www.kaggle.com/yasufuminakama/inchi-resnet-lstm-with-attention-starter) by Y. Nakama and [adapted to EfficientNets](https://www.kaggle.com/konradb/model-train-efficientnet) by Konrad Banachewicz. The notebook further extendens the pipeline by adding support for multi-layer LSTM in the decoder part. Most of the code changes are concentrated in the model class. Please credit the original authors for their contributions.\n",
    "\n",
    "This is training notebook. Inference with multi-layer LSTM decoder is demonstarted [in this notebook](https://www.kaggle.com/kozodoi/efficientnet-multi-layer-lstm-inference).\n",
    "\n",
    "### References:\n",
    "\n",
    "- [starter notebook from Y. Nakama](https://www.kaggle.com/yasufuminakama/inchi-resnet-lstm-with-attention-starter)\n",
    "- [adapted notebook from Konrad](https://www.kaggle.com/yasufuminakama/inchi-resnet-lstm-with-attention-starter)\n",
    "- [PyTorch tutorial on image captioning](https://github.com/sgrvinod/a-PyTorch-Tutorial-to-Image-Captioning)\n",
    "- [two-layer RNN implementation](https://github.com/sgrvinod/a-PyTorch-Tutorial-to-Image-Captioning/pull/79)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "complicated-skill",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-26T12:53:54.135657Z",
     "iopub.status.busy": "2021-04-26T12:53:54.134920Z",
     "iopub.status.idle": "2021-04-26T12:53:58.912458Z",
     "shell.execute_reply": "2021-04-26T12:53:58.911821Z"
    },
    "papermill": {
     "duration": 4.802785,
     "end_time": "2021-04-26T12:53:58.912619",
     "exception": false,
     "start_time": "2021-04-26T12:53:54.109834",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "OUTPUT_DIR = './'\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)\n",
    "    \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "import sys\n",
    "sys.path.append('../input/timm-pytorch-image-models/pytorch-image-models-master')\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import re\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import shutil\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from contextlib import contextmanager\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import Levenshtein\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, SGD\n",
    "import torchvision.models as models\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\n",
    "\n",
    "from albumentations import (\n",
    "    Compose, OneOf, Normalize, Resize, RandomResizedCrop, RandomCrop, HorizontalFlip, VerticalFlip, \n",
    "    RandomBrightness, RandomContrast, RandomBrightnessContrast, Rotate, ShiftScaleRotate, Cutout, \n",
    "    IAAAdditiveGaussianNoise, Transpose, Blur\n",
    "    )\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from albumentations import ImageOnlyTransform\n",
    "\n",
    "import timm\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "together-amino",
   "metadata": {
    "papermill": {
     "duration": 0.013476,
     "end_time": "2021-04-26T12:53:58.939553",
     "exception": false,
     "start_time": "2021-04-26T12:53:58.926077",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "CFG class now includes a new parameter: `decoder_layers`. For illustration purposes, I am running a two-layer LSTM for 1 epoch on 100k images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "tight-karma",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-26T12:53:58.972153Z",
     "iopub.status.busy": "2021-04-26T12:53:58.971429Z",
     "iopub.status.idle": "2021-04-26T12:53:58.975056Z",
     "shell.execute_reply": "2021-04-26T12:53:58.974623Z"
    },
    "papermill": {
     "duration": 0.022848,
     "end_time": "2021-04-26T12:53:58.975164",
     "exception": false,
     "start_time": "2021-04-26T12:53:58.952316",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#  n_channels_dict = {'efficientnet-b0': 1280, 'efficientnet-b1': 1280, 'efficientnet-b2': 1408,\n",
    "#   'efficientnet-b3': 1536, 'efficientnet-b4': 1792, 'efficientnet-b5': 2048,\n",
    "#   'efficientnet-b6': 2304, 'efficientnet-b7': 2560}\n",
    "\n",
    "# This is not, to put it mildly, the most elegant solution ever - but I ran into some trouble \n",
    "# with checking the size of feature spaces programmatically inside the CFG definition.\n",
    "\n",
    "class CFG:\n",
    "    debug          = False\n",
    "    apex           = False\n",
    "    max_len        = 275\n",
    "    print_freq     = 250\n",
    "    num_workers    = 16\n",
    "    model_name     = 'efficientnet_b2'\n",
    "    enc_size       = 1408\n",
    "    samp_size      = 100000\n",
    "    size           = 288\n",
    "    scheduler      = 'CosineAnnealingLR' \n",
    "    epochs         = 3\n",
    "    T_max          = 6\n",
    "    encoder_lr     = 1e-4\n",
    "    decoder_lr     = 4e-4\n",
    "    min_lr         = 1e-6\n",
    "    batch_size     = 64\n",
    "    weight_decay   = 1e-6\n",
    "    gradient_accumulation_steps = 1\n",
    "    max_grad_norm  = 10\n",
    "    attention_dim  = 256\n",
    "    embed_dim      = 512\n",
    "    decoder_dim    = 512\n",
    "    decoder_layers = 2     # number of LSTM layers\n",
    "    dropout        = 0.5\n",
    "    seed           = 32\n",
    "    n_fold         = 5\n",
    "    trn_fold       = 0 \n",
    "    train          = True\n",
    "    train_path     = '../data/train/'\n",
    "    synthetic_train_path = '../data/processed_synthetic_train_one_over/'\n",
    "    test_path     = '../data/test/'\n",
    "    prep_path      = './'\n",
    "    prev_model     = './efficientnet_b2_fold0_best_synthetic.pth'\n",
    "    start_epoch = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "competitive-moscow",
   "metadata": {
    "papermill": {
     "duration": 0.012553,
     "end_time": "2021-04-26T12:53:59.000553",
     "exception": false,
     "start_time": "2021-04-26T12:53:58.988000",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "convinced-turning",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-26T12:53:59.036727Z",
     "iopub.status.busy": "2021-04-26T12:53:59.035749Z",
     "iopub.status.idle": "2021-04-26T12:53:59.065709Z",
     "shell.execute_reply": "2021-04-26T12:53:59.066127Z"
    },
    "papermill": {
     "duration": 0.052982,
     "end_time": "2021-04-26T12:53:59.066302",
     "exception": false,
     "start_time": "2021-04-26T12:53:59.013320",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tokenizer.stoi: {'(': 0, ')': 1, '+': 2, ',': 3, '-': 4, '/b': 5, '/c': 6, '/h': 7, '/i': 8, '/m': 9, '/s': 10, '/t': 11, '0': 12, '1': 13, '10': 14, '100': 15, '101': 16, '102': 17, '103': 18, '104': 19, '105': 20, '106': 21, '107': 22, '108': 23, '109': 24, '11': 25, '110': 26, '111': 27, '112': 28, '113': 29, '114': 30, '115': 31, '116': 32, '117': 33, '118': 34, '119': 35, '12': 36, '120': 37, '121': 38, '122': 39, '123': 40, '124': 41, '125': 42, '126': 43, '127': 44, '128': 45, '129': 46, '13': 47, '130': 48, '131': 49, '132': 50, '133': 51, '134': 52, '135': 53, '136': 54, '137': 55, '138': 56, '139': 57, '14': 58, '140': 59, '141': 60, '142': 61, '143': 62, '144': 63, '145': 64, '146': 65, '147': 66, '148': 67, '149': 68, '15': 69, '150': 70, '151': 71, '152': 72, '153': 73, '154': 74, '155': 75, '156': 76, '157': 77, '158': 78, '159': 79, '16': 80, '161': 81, '163': 82, '165': 83, '167': 84, '17': 85, '18': 86, '19': 87, '2': 88, '20': 89, '21': 90, '22': 91, '23': 92, '24': 93, '25': 94, '26': 95, '27': 96, '28': 97, '29': 98, '3': 99, '30': 100, '31': 101, '32': 102, '33': 103, '34': 104, '35': 105, '36': 106, '37': 107, '38': 108, '39': 109, '4': 110, '40': 111, '41': 112, '42': 113, '43': 114, '44': 115, '45': 116, '46': 117, '47': 118, '48': 119, '49': 120, '5': 121, '50': 122, '51': 123, '52': 124, '53': 125, '54': 126, '55': 127, '56': 128, '57': 129, '58': 130, '59': 131, '6': 132, '60': 133, '61': 134, '62': 135, '63': 136, '64': 137, '65': 138, '66': 139, '67': 140, '68': 141, '69': 142, '7': 143, '70': 144, '71': 145, '72': 146, '73': 147, '74': 148, '75': 149, '76': 150, '77': 151, '78': 152, '79': 153, '8': 154, '80': 155, '81': 156, '82': 157, '83': 158, '84': 159, '85': 160, '86': 161, '87': 162, '88': 163, '89': 164, '9': 165, '90': 166, '91': 167, '92': 168, '93': 169, '94': 170, '95': 171, '96': 172, '97': 173, '98': 174, '99': 175, 'B': 176, 'Br': 177, 'C': 178, 'Cl': 179, 'D': 180, 'F': 181, 'H': 182, 'I': 183, 'N': 184, 'O': 185, 'P': 186, 'S': 187, 'Si': 188, 'T': 189, '<sos>': 190, '<eos>': 191, '<pad>': 192}\n"
     ]
    }
   ],
   "source": [
    "class Tokenizer(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.stoi = {}\n",
    "        self.itos = {}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.stoi)\n",
    "    \n",
    "    def fit_on_texts(self, texts):\n",
    "        vocab = set()\n",
    "        for text in texts:\n",
    "            vocab.update(text.split(' '))\n",
    "        vocab = sorted(vocab)\n",
    "        vocab.append('<sos>')\n",
    "        vocab.append('<eos>')\n",
    "        vocab.append('<pad>')\n",
    "        for i, s in enumerate(vocab):\n",
    "            self.stoi[s] = i\n",
    "        self.itos = {item[1]: item[0] for item in self.stoi.items()}\n",
    "        \n",
    "    def text_to_sequence(self, text):\n",
    "        sequence = []\n",
    "        sequence.append(self.stoi['<sos>'])\n",
    "        for s in text.split(' '):\n",
    "            sequence.append(self.stoi[s])\n",
    "        sequence.append(self.stoi['<eos>'])\n",
    "        return sequence\n",
    "    \n",
    "    def texts_to_sequences(self, texts):\n",
    "        sequences = []\n",
    "        for text in texts:\n",
    "            sequence = self.text_to_sequence(text)\n",
    "            sequences.append(sequence)\n",
    "        return sequences\n",
    "\n",
    "    def sequence_to_text(self, sequence):\n",
    "        return ''.join(list(map(lambda i: self.itos[i], sequence)))\n",
    "    \n",
    "    def sequences_to_texts(self, sequences):\n",
    "        texts = []\n",
    "        for sequence in sequences:\n",
    "            text = self.sequence_to_text(sequence)\n",
    "            texts.append(text)\n",
    "        return texts\n",
    "    \n",
    "    def predict_caption(self, sequence):\n",
    "        caption = ''\n",
    "        for i in sequence:\n",
    "            if i == self.stoi['<eos>'] or i == self.stoi['<pad>']:\n",
    "                break\n",
    "            caption += self.itos[i]\n",
    "        return caption\n",
    "    \n",
    "    def predict_captions(self, sequences):\n",
    "        captions = []\n",
    "        for sequence in sequences:\n",
    "            caption = self.predict_caption(sequence)\n",
    "            captions.append(caption)\n",
    "        return captions\n",
    "\n",
    "tokenizer = torch.load(CFG.prep_path + 'tokenizer.pth')\n",
    "print(f\"tokenizer.stoi: {tokenizer.stoi}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "broken-tunisia",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-26T12:53:59.103199Z",
     "iopub.status.busy": "2021-04-26T12:53:59.102552Z",
     "iopub.status.idle": "2021-04-26T12:53:59.108909Z",
     "shell.execute_reply": "2021-04-26T12:53:59.108415Z"
    },
    "papermill": {
     "duration": 0.028919,
     "end_time": "2021-04-26T12:53:59.109021",
     "exception": false,
     "start_time": "2021-04-26T12:53:59.080102",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_score(y_true, y_pred):\n",
    "    scores = []\n",
    "    for true, pred in zip(y_true, y_pred):\n",
    "        score = Levenshtein.distance(true, pred)\n",
    "        scores.append(score)\n",
    "    avg_score = np.mean(scores)\n",
    "    return avg_score\n",
    "\n",
    "\n",
    "def init_logger(log_file=OUTPUT_DIR+'train_synthetic.log'):\n",
    "    from logging import getLogger, INFO, FileHandler,  Formatter,  StreamHandler\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=log_file)\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "LOGGER = init_logger()\n",
    "\n",
    "\n",
    "def seed_torch(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_torch(seed = CFG.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cross-visibility",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-26T12:53:59.146264Z",
     "iopub.status.busy": "2021-04-26T12:53:59.143676Z",
     "iopub.status.idle": "2021-04-26T12:53:59.149421Z",
     "shell.execute_reply": "2021-04-26T12:53:59.149005Z"
    },
    "papermill": {
     "duration": 0.027172,
     "end_time": "2021-04-26T12:53:59.149575",
     "exception": false,
     "start_time": "2021-04-26T12:53:59.122403",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Dataset\n",
    "# ====================================================\n",
    "\n",
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, transform=None):\n",
    "        super().__init__()\n",
    "        self.df         = df\n",
    "        self.tokenizer  = tokenizer\n",
    "        self.file_paths = df['file_path'].values\n",
    "        self.labels     = df['InChI_text'].values\n",
    "        self.transform  = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        file_path = self.file_paths[idx]\n",
    "        image = cv2.imread(file_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image = image)\n",
    "            image     = augmented['image']\n",
    "        label = self.labels[idx]\n",
    "        label = self.tokenizer.text_to_sequence(label)\n",
    "        label_length = len(label)\n",
    "        label_length = torch.LongTensor([label_length])\n",
    "        return image, torch.LongTensor(label), label_length\n",
    "    \n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        self.file_paths = df['file_path'].values\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        file_path = self.file_paths[idx]\n",
    "        image = cv2.imread(file_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented['image']\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "intensive-norwegian",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-26T12:53:59.183682Z",
     "iopub.status.busy": "2021-04-26T12:53:59.181913Z",
     "iopub.status.idle": "2021-04-26T12:53:59.184334Z",
     "shell.execute_reply": "2021-04-26T12:53:59.184752Z"
    },
    "papermill": {
     "duration": 0.021826,
     "end_time": "2021-04-26T12:53:59.184877",
     "exception": false,
     "start_time": "2021-04-26T12:53:59.163051",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def bms_collate(batch):\n",
    "    imgs, labels, label_lengths = [], [], []\n",
    "    for data_point in batch:\n",
    "        imgs.append(data_point[0])\n",
    "        labels.append(data_point[1])\n",
    "        label_lengths.append(data_point[2])\n",
    "    labels = pad_sequence(labels, batch_first = True, padding_value = tokenizer.stoi[\"<pad>\"])\n",
    "    return torch.stack(imgs), labels, torch.stack(label_lengths).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "genuine-senate",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-26T12:53:59.217618Z",
     "iopub.status.busy": "2021-04-26T12:53:59.217064Z",
     "iopub.status.idle": "2021-04-26T12:53:59.221067Z",
     "shell.execute_reply": "2021-04-26T12:53:59.220631Z"
    },
    "papermill": {
     "duration": 0.022625,
     "end_time": "2021-04-26T12:53:59.221171",
     "exception": false,
     "start_time": "2021-04-26T12:53:59.198546",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "####### CNN ENCODER\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, model_name = CFG.model_name, pretrained = False):\n",
    "        super().__init__()\n",
    "        self.cnn = timm.create_model(model_name, pretrained = pretrained)\n",
    "\n",
    "    def forward(self, x):\n",
    "        bs       = x.size(0)\n",
    "        features = self.cnn.forward_features(x)\n",
    "        features = features.permute(0, 2, 3, 1)\n",
    "        return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "limiting-pressure",
   "metadata": {
    "papermill": {
     "duration": 0.013651,
     "end_time": "2021-04-26T12:53:59.248675",
     "exception": false,
     "start_time": "2021-04-26T12:53:59.235024",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The class `DecoderWithAttention` is updated to support a multi-layer LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "indirect-confidence",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-26T12:53:59.300860Z",
     "iopub.status.busy": "2021-04-26T12:53:59.284521Z",
     "iopub.status.idle": "2021-04-26T12:53:59.318375Z",
     "shell.execute_reply": "2021-04-26T12:53:59.318777Z"
    },
    "papermill": {
     "duration": 0.056587,
     "end_time": "2021-04-26T12:53:59.318921",
     "exception": false,
     "start_time": "2021-04-26T12:53:59.262334",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "####### RNN DECODER\n",
    "\n",
    "# attention module\n",
    "class Attention(nn.Module):\n",
    "    '''\n",
    "    Attention network for calculate attention value\n",
    "    '''\n",
    "    def __init__(self, encoder_dim, decoder_dim, attention_dim):\n",
    "        '''\n",
    "        :param encoder_dim: input size of encoder network\n",
    "        :param decoder_dim: input size of decoder network\n",
    "        :param attention_dim: input size of attention network\n",
    "        '''\n",
    "        super(Attention, self).__init__()\n",
    "        self.encoder_att = nn.Linear(encoder_dim, attention_dim)  # linear layer to transform encoded image\n",
    "        self.decoder_att = nn.Linear(decoder_dim, attention_dim)  # linear layer to transform decoder's output\n",
    "        self.full_att    = nn.Linear(attention_dim, 1)            # linear layer to calculate values to be softmax-ed\n",
    "        self.relu        = nn.ReLU()\n",
    "        self.softmax     = nn.Softmax(dim = 1)  # softmax layer to calculate weights\n",
    "\n",
    "    def forward(self, encoder_out, decoder_hidden):\n",
    "        att1  = self.encoder_att(encoder_out)     # (batch_size, num_pixels, attention_dim)\n",
    "        att2  = self.decoder_att(decoder_hidden)  # (batch_size, attention_dim)\n",
    "        att   = self.full_att(self.relu(att1 + att2.unsqueeze(1))).squeeze(2)  # (batch_size, num_pixels)\n",
    "        alpha = self.softmax(att)                 # (batch_size, num_pixels)\n",
    "        attention_weighted_encoding = (encoder_out * alpha.unsqueeze(2)).sum(dim = 1)  # (batch_size, encoder_dim)\n",
    "        return attention_weighted_encoding, alpha\n",
    "    \n",
    "    \n",
    "# custom LSTM cell\n",
    "def LSTMCell(input_size, hidden_size, **kwargs):\n",
    "    m = nn.LSTMCell(input_size, hidden_size, **kwargs)\n",
    "    for name, param in m.named_parameters():\n",
    "        if 'weight' in name or 'bias' in name:\n",
    "            param.data.uniform_(-0.1, 0.1)\n",
    "    return m\n",
    "\n",
    "\n",
    "# decoder\n",
    "class DecoderWithAttention(nn.Module):\n",
    "    '''\n",
    "    Decoder network with attention network used for training\n",
    "    '''\n",
    "\n",
    "    def __init__(self, attention_dim, embed_dim, decoder_dim, vocab_size, device, encoder_dim, dropout, num_layers):\n",
    "        '''\n",
    "        :param attention_dim: input size of attention network\n",
    "        :param embed_dim: input size of embedding network\n",
    "        :param decoder_dim: input size of decoder network\n",
    "        :param vocab_size: total number of characters used in training\n",
    "        :param encoder_dim: input size of encoder network\n",
    "        :param num_layers: number of the LSTM layers\n",
    "        :param dropout: dropout rate\n",
    "        '''\n",
    "        super(DecoderWithAttention, self).__init__()\n",
    "        self.encoder_dim   = encoder_dim\n",
    "        self.attention_dim = attention_dim\n",
    "        self.embed_dim     = embed_dim\n",
    "        self.decoder_dim   = decoder_dim\n",
    "        self.vocab_size    = vocab_size\n",
    "        self.dropout       = dropout\n",
    "        self.num_layers    = num_layers\n",
    "        self.device        = device\n",
    "        self.attention     = Attention(encoder_dim, decoder_dim, attention_dim)  # attention network\n",
    "        self.embedding     = nn.Embedding(vocab_size, embed_dim)                 # embedding layer\n",
    "        self.dropout       = nn.Dropout(p = self.dropout)\n",
    "        self.decode_step   = nn.ModuleList([LSTMCell(embed_dim + encoder_dim if layer == 0 else embed_dim, embed_dim) for layer in range(self.num_layers)]) # decoding LSTMCell        \n",
    "        self.init_h        = nn.Linear(encoder_dim, decoder_dim)  # linear layer to find initial hidden state of LSTMCell\n",
    "        self.init_c        = nn.Linear(encoder_dim, decoder_dim)  # linear layer to find initial cell state of LSTMCell\n",
    "        self.f_beta        = nn.Linear(decoder_dim, encoder_dim)  # linear layer to create a sigmoid-activated gate\n",
    "        self.sigmoid       = nn.Sigmoid()\n",
    "        self.fc            = nn.Linear(decoder_dim, vocab_size)  # linear layer to find scores over vocabulary\n",
    "        self.init_weights()                                      # initialize some layers with the uniform distribution\n",
    "\n",
    "    def init_weights(self):\n",
    "        self.embedding.weight.data.uniform_(-0.1, 0.1)\n",
    "        self.fc.bias.data.fill_(0)\n",
    "        self.fc.weight.data.uniform_(-0.1, 0.1)\n",
    "\n",
    "    def load_pretrained_embeddings(self, embeddings):\n",
    "        self.embedding.weight = nn.Parameter(embeddings)\n",
    "\n",
    "    def fine_tune_embeddings(self, fine_tune = True):\n",
    "        for p in self.embedding.parameters():\n",
    "            p.requires_grad = fine_tune\n",
    "\n",
    "    def init_hidden_state(self, encoder_out):\n",
    "        mean_encoder_out = encoder_out.mean(dim = 1)\n",
    "        h = [self.init_h(mean_encoder_out) for i in range(self.num_layers)]  # (batch_size, decoder_dim)\n",
    "        c = [self.init_c(mean_encoder_out) for i in range(self.num_layers)]\n",
    "        return h, c\n",
    "\n",
    "    def forward(self, encoder_out, encoded_captions, caption_lengths):\n",
    "        '''\n",
    "        :param encoder_out: output of encoder network\n",
    "        :param encoded_captions: transformed sequence from character to integer\n",
    "        :param caption_lengths: length of transformed sequence\n",
    "        '''\n",
    "        batch_size       = encoder_out.size(0)\n",
    "        encoder_dim      = encoder_out.size(-1)\n",
    "        vocab_size       = self.vocab_size\n",
    "        encoder_out      = encoder_out.view(batch_size, -1, encoder_dim)  # (batch_size, num_pixels, encoder_dim)\n",
    "        num_pixels       = encoder_out.size(1)\n",
    "        caption_lengths, sort_ind = caption_lengths.squeeze(1).sort(dim = 0, descending = True)\n",
    "        encoder_out      = encoder_out[sort_ind]\n",
    "        encoded_captions = encoded_captions[sort_ind]\n",
    "        \n",
    "        # embedding transformed sequence for vector\n",
    "        embeddings = self.embedding(encoded_captions)  # (batch_size, max_caption_length, embed_dim)\n",
    "        \n",
    "        # Initialize LSTM state, initialize cell_vector and hidden_vector\n",
    "        prev_h, prev_c = self.init_hidden_state(encoder_out)  # (batch_size, decoder_dim)\n",
    "        \n",
    "        # set decode length by caption length - 1 because of omitting start token\n",
    "        decode_lengths = (caption_lengths - 1).tolist()\n",
    "        predictions    = torch.zeros(batch_size, max(decode_lengths), vocab_size, device = self.device)\n",
    "        alphas         = torch.zeros(batch_size, max(decode_lengths), num_pixels, device = self.device)\n",
    "        \n",
    "        # predict sequence\n",
    "        for t in range(max(decode_lengths)):\n",
    "            batch_size_t = sum([l > t for l in decode_lengths])\n",
    "            attention_weighted_encoding, alpha = self.attention(encoder_out[:batch_size_t],\n",
    "                                                                prev_h[-1][:batch_size_t])\n",
    "            gate = self.sigmoid(self.f_beta(prev_h[-1][:batch_size_t]))  # gating scalar, (batch_size_t, encoder_dim)\n",
    "            attention_weighted_encoding = gate * attention_weighted_encoding\n",
    "\n",
    "            input = torch.cat([embeddings[:batch_size_t, t, :], attention_weighted_encoding], dim=1)\n",
    "            \n",
    "            for i, rnn in enumerate(self.decode_step):\n",
    "                # recurrent cell\n",
    "                h, c = rnn(input, (prev_h[i][:batch_size_t], prev_c[i][:batch_size_t])) # cell_vector and hidden_vector\n",
    "\n",
    "                # hidden state becomes the input to the next layer\n",
    "                input = self.dropout(h)\n",
    "\n",
    "                # save state for next time step\n",
    "                prev_h[i] = h\n",
    "                prev_c[i] = c\n",
    "                \n",
    "            preds = self.fc(self.dropout(h))  # (batch_size_t, vocab_size)\n",
    "            predictions[:batch_size_t, t, :] = preds\n",
    "            alphas[:batch_size_t, t, :]      = alpha\n",
    "            \n",
    "        return predictions, encoded_captions, decode_lengths, alphas, sort_ind\n",
    "    \n",
    "    def predict(self, encoder_out, decode_lengths, tokenizer):\n",
    "        \n",
    "        # size variables\n",
    "        batch_size  = encoder_out.size(0)\n",
    "        encoder_dim = encoder_out.size(-1)\n",
    "        vocab_size  = self.vocab_size\n",
    "        encoder_out = encoder_out.view(batch_size, -1, encoder_dim)  # (batch_size, num_pixels, encoder_dim)\n",
    "        num_pixels  = encoder_out.size(1)\n",
    "        \n",
    "        # embed start tocken for LSTM input\n",
    "        start_tockens = torch.ones(batch_size, dtype = torch.long, device = self.device) * tokenizer.stoi['<sos>']\n",
    "        embeddings    = self.embedding(start_tockens)\n",
    "        \n",
    "        # initialize hidden state and cell state of LSTM cell\n",
    "        h, c        = self.init_hidden_state(encoder_out)  # (batch_size, decoder_dim)\n",
    "        predictions = torch.zeros(batch_size, decode_lengths, vocab_size, device = self.device)\n",
    "        \n",
    "        # predict sequence\n",
    "        end_condition = torch.zeros(batch_size, dtype=torch.long, device = self.device)\n",
    "        for t in range(decode_lengths):\n",
    "            awe, alpha = self.attention(encoder_out, h[-1])  # (s, encoder_dim), (s, num_pixels)\n",
    "            gate       = self.sigmoid(self.f_beta(h[-1]))    # gating scalar, (s, encoder_dim)\n",
    "            awe        = gate * awe\n",
    "            \n",
    "            input = torch.cat([embeddings, awe], dim=1)\n",
    " \n",
    "            for j, rnn in enumerate(self.decode_step):\n",
    "                at_h, at_c = rnn(input, (h[j], c[j]))  # (s, decoder_dim)\n",
    "                input = self.dropout(at_h)\n",
    "                h[j]  = at_h\n",
    "                c[j]  = at_c\n",
    "            \n",
    "            preds = self.fc(self.dropout(h[-1]))  # (batch_size_t, vocab_size)\n",
    "            predictions[:, t, :] = preds\n",
    "            end_condition |= (torch.argmax(preds, -1) == tokenizer.stoi[\"<eos>\"])\n",
    "            if end_condition.sum() == batch_size:\n",
    "                break\n",
    "            embeddings = self.embedding(torch.argmax(preds, -1))\n",
    "        \n",
    "        return predictions\n",
    "    \n",
    "    # beam search\n",
    "    def forward_step(self, prev_tokens, hidden, encoder_out, function):\n",
    "        \n",
    "        h, c = hidden\n",
    "        #h, c = h.squeeze(0), c.squeeze(0)\n",
    "        h, c = [hi.squeeze(0) for hi in h], [ci.squeeze(0) for ci in c]\n",
    "        \n",
    "        embeddings = self.embedding(prev_tokens)\n",
    "        if embeddings.dim() == 3:\n",
    "            embeddings = embeddings.squeeze(1)\n",
    "            \n",
    "        awe, alpha = self.attention(encoder_out, h[-1])  # (s, encoder_dim), (s, num_pixels)\n",
    "        gate       = self.sigmoid(self.f_beta(h[-1]))    # gating scalar, (s, encoder_dim)\n",
    "        awe        = gate * awe\n",
    "        \n",
    "        input = torch.cat([embeddings, awe], dim = 1)\n",
    "        for j, rnn in enumerate(self.decode_step):\n",
    "            at_h, at_c = rnn(input, (h[j], c[j]))  # (s, decoder_dim)\n",
    "            input = self.dropout(at_h)\n",
    "            h[j]  = at_h\n",
    "            c[j]  = at_c\n",
    "\n",
    "        preds = self.fc(self.dropout(h[-1]))  # (batch_size_t, vocab_size)\n",
    "\n",
    "        #hidden = (h.unsqueeze(0), c.unsqueeze(0))\n",
    "        hidden = [hi.unsqueeze(0) for hi in h], [ci.unsqueeze(0) for ci in c]\n",
    "        predicted_softmax = function(preds, dim = 1)\n",
    "        \n",
    "        return predicted_softmax, hidden, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "czech-actress",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-26T12:53:59.369806Z",
     "iopub.status.busy": "2021-04-26T12:53:59.368965Z",
     "iopub.status.idle": "2021-04-26T12:53:59.379265Z",
     "shell.execute_reply": "2021-04-26T12:53:59.378785Z"
    },
    "papermill": {
     "duration": 0.043018,
     "end_time": "2021-04-26T12:53:59.379363",
     "exception": false,
     "start_time": "2021-04-26T12:53:59.336345",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val   = 0\n",
    "        self.avg   = 0\n",
    "        self.sum   = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val    = val\n",
    "        self.sum   += val * n\n",
    "        self.count += n\n",
    "        self.avg    = self.sum / self.count\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s   = now - since\n",
    "    es  = s / (percent)\n",
    "    rs  = es - s\n",
    "    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "\n",
    "def train_fn(train_loader, encoder, decoder, criterion, \n",
    "             encoder_optimizer, decoder_optimizer, epoch,\n",
    "             encoder_scheduler, decoder_scheduler, device):\n",
    "    \n",
    "    batch_time = AverageMeter()\n",
    "    data_time  = AverageMeter()\n",
    "    losses     = AverageMeter()\n",
    "    \n",
    "    # switch to train mode\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "    \n",
    "    start = end = time.time()\n",
    "    global_step = 0\n",
    "    \n",
    "    for step, (images, labels, label_lengths) in enumerate(train_loader):\n",
    "        \n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "        \n",
    "        images        = images.to(device)\n",
    "        labels        = labels.to(device)\n",
    "        label_lengths = label_lengths.to(device)\n",
    "        batch_size    = images.size(0)\n",
    "        \n",
    "        features = encoder(images)\n",
    "        predictions, caps_sorted, decode_lengths, alphas, sort_ind = decoder(features, labels, label_lengths)\n",
    "        targets     = caps_sorted[:, 1:]\n",
    "        predictions = pack_padded_sequence(predictions, decode_lengths, batch_first=True).data\n",
    "        targets     = pack_padded_sequence(targets, decode_lengths, batch_first=True).data\n",
    "        loss        = criterion(predictions, targets)\n",
    "        \n",
    "        # record loss\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        if CFG.gradient_accumulation_steps > 1:\n",
    "            loss = loss / CFG.gradient_accumulation_steps\n",
    "            \n",
    "        if CFG.apex:\n",
    "            with amp.scale_loss(loss, decoder_optimizer) as scaled_loss:\n",
    "                scaled_loss.backward()\n",
    "        else:\n",
    "            loss.backward()\n",
    "            \n",
    "        encoder_grad_norm = torch.nn.utils.clip_grad_norm_(encoder.parameters(), CFG.max_grad_norm)\n",
    "        decoder_grad_norm = torch.nn.utils.clip_grad_norm_(decoder.parameters(), CFG.max_grad_norm)\n",
    "        \n",
    "        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n",
    "            encoder_optimizer.step()\n",
    "            decoder_optimizer.step()\n",
    "            encoder_optimizer.zero_grad()\n",
    "            decoder_optimizer.zero_grad()\n",
    "            global_step += 1\n",
    "            \n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        if step == len(train_loader) // 2:\n",
    "            encoder_scheduler.step()\n",
    "            decoder_scheduler.step()\n",
    "        if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n",
    "            print('Epoch: [{0}][{1}/{2}] '\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f}) '\n",
    "                  'Elapsed {remain:s} '\n",
    "                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                  'Encoder Grad: {encoder_grad_norm:.4f}  '\n",
    "                  'Decoder Grad: {decoder_grad_norm:.4f}  '\n",
    "                  'Encoder LR: {encoder_lr:.6f}  '\n",
    "                  'Decoder LR: {decoder_lr:.6f}  '\n",
    "                  .format(\n",
    "                   epoch+1, step, len(train_loader), \n",
    "                   batch_time        = batch_time,\n",
    "                   data_time         = data_time, \n",
    "                   loss              = losses,\n",
    "                   remain            = timeSince(start, float(step+1)/len(train_loader)),\n",
    "                   encoder_grad_norm = encoder_grad_norm,\n",
    "                   decoder_grad_norm = decoder_grad_norm,\n",
    "                   encoder_lr=encoder_scheduler.get_lr()[0],\n",
    "                   decoder_lr=decoder_scheduler.get_lr()[0],\n",
    "                   ))\n",
    "    return losses.avg\n",
    "\n",
    "\n",
    "def valid_fn(valid_loader, encoder, decoder, tokenizer, criterion, device):\n",
    "    \n",
    "    batch_time = AverageMeter()\n",
    "    data_time  = AverageMeter()\n",
    "    \n",
    "    # switch to evaluation mode\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    \n",
    "    text_preds = []\n",
    "    start = end = time.time()\n",
    "    \n",
    "    for step, (images) in enumerate(valid_loader):\n",
    "        \n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "        \n",
    "        images     = images.to(device)\n",
    "        batch_size = images.size(0)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            features    = encoder(images)\n",
    "            predictions = decoder.predict(features, CFG.max_len, tokenizer)\n",
    "            \n",
    "        predicted_sequence = torch.argmax(predictions.detach().cpu(), -1).numpy()\n",
    "        _text_preds        = tokenizer.predict_captions(predicted_sequence)\n",
    "        text_preds.append(_text_preds)\n",
    "        \n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n",
    "            print('EVAL: [{0}/{1}] '\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f}) '\n",
    "                  'Elapsed {remain:s} '\n",
    "                  .format(\n",
    "                   step, len(valid_loader), \n",
    "                   batch_time = batch_time,\n",
    "                   data_time  = data_time,\n",
    "                   remain     = timeSince(start, float(step+1)/len(valid_loader)),\n",
    "                   ))\n",
    "            \n",
    "    text_preds = np.concatenate(text_preds)\n",
    "    return text_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "established-grace",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-26T12:53:59.421890Z",
     "iopub.status.busy": "2021-04-26T12:53:59.421034Z",
     "iopub.status.idle": "2021-04-26T12:53:59.436873Z",
     "shell.execute_reply": "2021-04-26T12:53:59.436213Z"
    },
    "papermill": {
     "duration": 0.040724,
     "end_time": "2021-04-26T12:53:59.437011",
     "exception": false,
     "start_time": "2021-04-26T12:53:59.396287",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Train loop\n",
    "# ====================================================\n",
    "def train_loop(folds, synthetic_folds, fold):\n",
    "\n",
    "    LOGGER.info(f\"========== fold: {fold} training ==========\")\n",
    "\n",
    "    # ====================================================\n",
    "    # loader\n",
    "    # ====================================================\n",
    "    trn_idx = folds[folds['fold'] != fold].index\n",
    "    val_idx = folds[folds['fold'] == fold].index\n",
    "\n",
    "    train_folds  = folds.loc[trn_idx].reset_index(drop = True)\n",
    "    valid_folds  = folds.loc[val_idx].reset_index(drop = True)\n",
    "    valid_labels = valid_folds['InChI'].values\n",
    "\n",
    "    synthetic_trn_idx = synthetic_folds[synthetic_folds['fold'] != fold].index\n",
    "    synthetic_val_idx = synthetic_folds[synthetic_folds['fold'] == fold].index\n",
    "\n",
    "    synthetic_train_folds  = synthetic_folds.loc[synthetic_trn_idx].reset_index(drop = True)\n",
    "    synthetic_valid_folds  = synthetic_folds.loc[synthetic_val_idx].reset_index(drop = True)\n",
    "    synthetic_valid_labels = synthetic_valid_folds['InChI'].values\n",
    "\n",
    "    train_dataset = TrainDataset(train_folds, tokenizer, transform = get_transforms(data = 'train'))\n",
    "    valid_dataset = TestDataset(valid_folds, transform = get_transforms(data = 'valid'))\n",
    "\n",
    "    synthetic_train_dataset = TrainDataset(synthetic_train_folds, tokenizer, transform = get_transforms(data = 'train'))\n",
    "    synthetic_valid_dataset = TestDataset(synthetic_valid_folds, transform = get_transforms(data = 'valid'))\n",
    "\n",
    "    combined_train_dataset = torch.utils.data.ConcatDataset([train_dataset, synthetic_train_dataset])\n",
    "    combined_valid_dataset = torch.utils.data.ConcatDataset([valid_dataset, synthetic_valid_dataset])\n",
    "\n",
    "    train_loader = DataLoader(combined_train_dataset, \n",
    "                              batch_size  = CFG.batch_size, \n",
    "                              shuffle     = True, \n",
    "                              num_workers = CFG.num_workers, \n",
    "                              pin_memory  = True,\n",
    "                              drop_last   = True, \n",
    "                              collate_fn  = bms_collate)\n",
    "    valid_loader = DataLoader(combined_valid_dataset, \n",
    "                              batch_size  = CFG.batch_size, \n",
    "                              shuffle     = False, \n",
    "                              num_workers = CFG.num_workers,\n",
    "                              pin_memory  = True, \n",
    "                              drop_last   = False)\n",
    "    \n",
    "    # ====================================================\n",
    "    # scheduler \n",
    "    # ====================================================\n",
    "    def get_scheduler(optimizer):\n",
    "        if CFG.scheduler=='ReduceLROnPlateau':\n",
    "            scheduler = ReduceLROnPlateau(optimizer, \n",
    "                                          mode     = 'min', \n",
    "                                          factor   = CFG.factor, \n",
    "                                          patience = CFG.patience, \n",
    "                                          verbose  = True, \n",
    "                                          eps      = CFG.eps)\n",
    "        elif CFG.scheduler=='CosineAnnealingLR':\n",
    "            scheduler = CosineAnnealingLR(optimizer, \n",
    "                                          T_max      = CFG.T_max, \n",
    "                                          eta_min    = CFG.min_lr, \n",
    "                                          last_epoch = -1)\n",
    "        elif CFG.scheduler=='CosineAnnealingWarmRestarts':\n",
    "            scheduler = CosineAnnealingWarmRestarts(optimizer, \n",
    "                                                    T_0        = CFG.T_0, \n",
    "                                                    T_mult     = 1, \n",
    "                                                    eta_min    = CFG.min_lr, \n",
    "                                                    last_epoch = -1)\n",
    "        return scheduler\n",
    "\n",
    "    # ====================================================\n",
    "    # model & optimizer\n",
    "    # ====================================================\n",
    "\n",
    "    states = torch.load(CFG.prev_model,  map_location=torch.device('cpu'))\n",
    "\n",
    "    encoder = Encoder(CFG.model_name, \n",
    "                      pretrained = True)\n",
    "    encoder.load_state_dict(states['encoder'])\n",
    "    \n",
    "    encoder.to(device)\n",
    "    encoder_optimizer = Adam(encoder.parameters(), \n",
    "                             lr           = CFG.encoder_lr, \n",
    "                             weight_decay = CFG.weight_decay, \n",
    "                             amsgrad      = False)\n",
    "    encoder_optimizer.load_state_dict(states['encoder_optimizer'])\n",
    "    encoder_scheduler = get_scheduler(encoder_optimizer)\n",
    "    encoder_scheduler.load_state_dict(states['encoder_scheduler'])\n",
    "    \n",
    "    decoder = DecoderWithAttention(attention_dim = CFG.attention_dim, \n",
    "                                   embed_dim     = CFG.embed_dim, \n",
    "                                   encoder_dim   = CFG.enc_size,\n",
    "                                   decoder_dim   = CFG.decoder_dim,\n",
    "                                   num_layers    = CFG.decoder_layers,\n",
    "                                   vocab_size    = len(tokenizer), \n",
    "                                   dropout       = CFG.dropout, \n",
    "                                   device        = device)\n",
    "    decoder.load_state_dict(states['decoder'])\n",
    "    decoder.to(device)\n",
    "    decoder_optimizer = Adam(decoder.parameters(), \n",
    "                             lr           = CFG.decoder_lr, \n",
    "                             weight_decay = CFG.weight_decay, \n",
    "                             amsgrad      = False)\n",
    "    decoder_optimizer.load_state_dict(states['decoder_optimizer'])\n",
    "\n",
    "    decoder_scheduler = get_scheduler(decoder_optimizer)\n",
    "    decoder_scheduler.load_state_dict(states['decoder_scheduler'])\n",
    "\n",
    "    # ====================================================\n",
    "    # loop\n",
    "    # ====================================================\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index = tokenizer.stoi[\"<pad>\"])\n",
    "\n",
    "    best_score = np.inf\n",
    "    best_loss  = np.inf\n",
    "    \n",
    "    for epoch in range(CFG.start_epoch, CFG.epochs):\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        # train\n",
    "        avg_loss = train_fn(train_loader, encoder, decoder, criterion, \n",
    "                            encoder_optimizer, decoder_optimizer, epoch, \n",
    "                            encoder_scheduler, decoder_scheduler, device)\n",
    "\n",
    "        # eval\n",
    "        text_preds = valid_fn(valid_loader, encoder, decoder, tokenizer, criterion, device)\n",
    "        text_preds = [f\"InChI=1S/{text}\" for text in text_preds]\n",
    "        LOGGER.info(f\"labels: {valid_labels[:5]}\")\n",
    "        LOGGER.info(f\"preds: {text_preds[:5]}\")\n",
    "        \n",
    "        # scoring\n",
    "        score = get_score(valid_labels, text_preds)\n",
    "        \n",
    "        if isinstance(encoder_scheduler, ReduceLROnPlateau):\n",
    "            encoder_scheduler.step(score)\n",
    "        elif isinstance(encoder_scheduler, CosineAnnealingLR):\n",
    "            encoder_scheduler.step()\n",
    "        elif isinstance(encoder_scheduler, CosineAnnealingWarmRestarts):\n",
    "            encoder_scheduler.step()\n",
    "            \n",
    "        if isinstance(decoder_scheduler, ReduceLROnPlateau):\n",
    "            decoder_scheduler.step(score)\n",
    "        elif isinstance(decoder_scheduler, CosineAnnealingLR):\n",
    "            decoder_scheduler.step()\n",
    "        elif isinstance(decoder_scheduler, CosineAnnealingWarmRestarts):\n",
    "            decoder_scheduler.step()\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "\n",
    "        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  time: {elapsed:.0f}s')\n",
    "        LOGGER.info(f'Epoch {epoch+1} - Score: {score:.4f}')\n",
    "        \n",
    "        if score < best_score:\n",
    "            best_score = score\n",
    "            LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n",
    "            torch.save({'encoder': encoder.state_dict(), \n",
    "                        'encoder_optimizer': encoder_optimizer.state_dict(), \n",
    "                        'encoder_scheduler': encoder_scheduler.state_dict(), \n",
    "                        'decoder': decoder.state_dict(), \n",
    "                        'decoder_optimizer': decoder_optimizer.state_dict(), \n",
    "                        'decoder_scheduler': decoder_scheduler.state_dict(), \n",
    "                        'text_preds': text_preds,\n",
    "                       },\n",
    "                        OUTPUT_DIR+f'{CFG.model_name}_fold{fold}_best_synthetic.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "separated-giant",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-26T12:53:59.470875Z",
     "iopub.status.busy": "2021-04-26T12:53:59.470259Z",
     "iopub.status.idle": "2021-04-26T12:53:59.473099Z",
     "shell.execute_reply": "2021-04-26T12:53:59.472709Z"
    },
    "papermill": {
     "duration": 0.021246,
     "end_time": "2021-04-26T12:53:59.473210",
     "exception": false,
     "start_time": "2021-04-26T12:53:59.451964",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_train_file_path(image_id):\n",
    "\n",
    "    return CFG.train_path + \"{}/{}/{}/{}.png\".format(\n",
    "        image_id[0], image_id[1], image_id[2], image_id \n",
    "    )\n",
    "\n",
    "def get_synthetic_train_file_path(image_id):\n",
    "\n",
    "    return CFG.synthetic_train_path + \"{}/{}/{}/{}.png\".format(\n",
    "        image_id[0], image_id[1], image_id[2], image_id \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "comprehensive-lithuania",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-26T12:53:59.509980Z",
     "iopub.status.busy": "2021-04-26T12:53:59.509278Z",
     "iopub.status.idle": "2021-04-26T12:53:59.512165Z",
     "shell.execute_reply": "2021-04-26T12:53:59.511778Z"
    },
    "papermill": {
     "duration": 0.023526,
     "end_time": "2021-04-26T12:53:59.512265",
     "exception": false,
     "start_time": "2021-04-26T12:53:59.488739",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# transformations\n",
    "\n",
    "def get_transforms(*, data):\n",
    "    \n",
    "    if data == 'train':\n",
    "        return Compose([\n",
    "            Resize(CFG.size, CFG.size),\n",
    "            HorizontalFlip(p=0.5),                  \n",
    "            Transpose(p=0.5),\n",
    "            HorizontalFlip(p=0.5),\n",
    "            VerticalFlip(p=0.5),\n",
    "            ShiftScaleRotate(p=0.5),   \n",
    "            Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225],\n",
    "            ),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "    \n",
    "    elif data == 'valid':\n",
    "        return Compose([\n",
    "            Resize(CFG.size, CFG.size),\n",
    "            Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225],\n",
    "            ),\n",
    "            ToTensorV2(),\n",
    "        ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "painful-weight",
   "metadata": {
    "papermill": {
     "duration": 0.01535,
     "end_time": "2021-04-26T12:53:59.543526",
     "exception": false,
     "start_time": "2021-04-26T12:53:59.528176",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ranking-marshall",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-26T12:53:59.578109Z",
     "iopub.status.busy": "2021-04-26T12:53:59.577313Z",
     "iopub.status.idle": "2021-04-26T12:54:13.176722Z",
     "shell.execute_reply": "2021-04-26T12:54:13.175920Z"
    },
    "papermill": {
     "duration": 13.618271,
     "end_time": "2021-04-26T12:54:13.176857",
     "exception": false,
     "start_time": "2021-04-26T12:53:59.558586",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "train.shape: (2424186, 6)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_pickle(CFG.prep_path + 'train.pkl')\n",
    "synthetic_train = pd.read_pickle(CFG.prep_path + 'train.pkl')\n",
    "\n",
    "train['file_path'] = train['image_id'].apply(get_train_file_path)\n",
    "synthetic_train['file_path'] = synthetic_train['image_id'].apply(get_synthetic_train_file_path)\n",
    "\n",
    "print(f'train.shape: {train.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "chicken-tuesday",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-26T12:54:13.213502Z",
     "iopub.status.busy": "2021-04-26T12:54:13.212692Z",
     "iopub.status.idle": "2021-04-26T12:54:13.285258Z",
     "shell.execute_reply": "2021-04-26T12:54:13.284782Z"
    },
    "papermill": {
     "duration": 0.093227,
     "end_time": "2021-04-26T12:54:13.285370",
     "exception": false,
     "start_time": "2021-04-26T12:54:13.192143",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "folds = train.copy()\n",
    "synthetic_folds = synthetic_train.copy()\n",
    "\n",
    "Fold = StratifiedKFold(n_splits = CFG.n_fold, shuffle = True, random_state = CFG.seed)\n",
    "\n",
    "for n, (train_index, val_index) in enumerate(Fold.split(folds, folds['InChI_length'])):\n",
    "    folds.loc[val_index, 'fold'] = int(n)\n",
    "\n",
    "folds['fold'] = folds['fold'].astype(int)\n",
    "\n",
    "for n, (train_index, val_index) in enumerate(Fold.split(synthetic_folds, synthetic_folds['InChI_length'])):\n",
    "    synthetic_folds.loc[val_index, 'fold'] = int(n)\n",
    "\n",
    "synthetic_folds['fold'] = synthetic_folds['fold'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shared-manual",
   "metadata": {
    "papermill": {
     "duration": 0.014371,
     "end_time": "2021-04-26T12:54:13.314571",
     "exception": false,
     "start_time": "2021-04-26T12:54:13.300200",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "distributed-wilson",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-26T12:54:13.348037Z",
     "iopub.status.busy": "2021-04-26T12:54:13.347383Z",
     "iopub.status.idle": "2021-04-26T13:34:06.421828Z",
     "shell.execute_reply": "2021-04-26T13:34:06.421275Z"
    },
    "papermill": {
     "duration": 2393.0926,
     "end_time": "2021-04-26T13:34:06.421981",
     "exception": false,
     "start_time": "2021-04-26T12:54:13.329381",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "========== fold: 0 training ==========\n",
      "Epoch: [3][0/60604] Data 3.578 (3.578) Elapsed 0m 5s (remain 5265m 47s) Loss: 0.0781(0.0781) Encoder Grad: 0.6207  Decoder Grad: 0.2579  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][250/60604] Data 0.000 (0.014) Elapsed 2m 42s (remain 649m 29s) Loss: 0.0936(0.1076) Encoder Grad: 0.4582  Decoder Grad: 0.2118  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][500/60604] Data 0.000 (0.007) Elapsed 5m 17s (remain 634m 6s) Loss: 0.1377(0.1101) Encoder Grad: 0.7270  Decoder Grad: 0.2948  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][750/60604] Data 0.000 (0.005) Elapsed 7m 55s (remain 631m 53s) Loss: 0.1203(0.1107) Encoder Grad: 0.5156  Decoder Grad: 0.2189  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][1000/60604] Data 0.000 (0.004) Elapsed 10m 30s (remain 625m 24s) Loss: 0.0804(0.1114) Encoder Grad: 0.4622  Decoder Grad: 0.2224  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][1250/60604] Data 0.000 (0.003) Elapsed 12m 55s (remain 613m 26s) Loss: 0.0877(0.1118) Encoder Grad: 0.6399  Decoder Grad: 0.1782  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][1500/60604] Data 0.000 (0.002) Elapsed 15m 23s (remain 605m 48s) Loss: 0.1109(0.1117) Encoder Grad: 0.6201  Decoder Grad: 0.2095  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][1750/60604] Data 0.000 (0.002) Elapsed 17m 55s (remain 602m 28s) Loss: 0.1046(0.1119) Encoder Grad: 0.4479  Decoder Grad: 0.2581  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][2000/60604] Data 0.000 (0.002) Elapsed 20m 35s (remain 603m 13s) Loss: 0.0701(0.1119) Encoder Grad: 0.3845  Decoder Grad: 0.1806  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][2250/60604] Data 0.000 (0.002) Elapsed 23m 16s (remain 603m 8s) Loss: 0.0997(0.1118) Encoder Grad: 0.8033  Decoder Grad: 0.2002  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][2500/60604] Data 0.000 (0.002) Elapsed 25m 58s (remain 603m 15s) Loss: 0.1259(0.1117) Encoder Grad: 0.4144  Decoder Grad: 0.1759  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][2750/60604] Data 0.000 (0.001) Elapsed 28m 32s (remain 600m 4s) Loss: 0.1169(0.1121) Encoder Grad: 0.4387  Decoder Grad: 0.2031  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][3000/60604] Data 0.000 (0.001) Elapsed 30m 57s (remain 594m 16s) Loss: 0.1327(0.1122) Encoder Grad: 0.4363  Decoder Grad: 0.1750  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][3250/60604] Data 0.000 (0.001) Elapsed 33m 24s (remain 589m 17s) Loss: 0.1953(0.1124) Encoder Grad: 0.6418  Decoder Grad: 0.2358  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][3500/60604] Data 0.000 (0.001) Elapsed 35m 49s (remain 584m 13s) Loss: 0.0794(0.1126) Encoder Grad: 0.3634  Decoder Grad: 0.1615  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][3750/60604] Data 0.000 (0.001) Elapsed 38m 15s (remain 579m 55s) Loss: 0.0854(0.1126) Encoder Grad: 0.5191  Decoder Grad: 0.2108  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][4000/60604] Data 0.000 (0.001) Elapsed 40m 42s (remain 575m 52s) Loss: 0.1129(0.1126) Encoder Grad: 0.5646  Decoder Grad: 0.2373  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][4250/60604] Data 0.000 (0.001) Elapsed 43m 8s (remain 571m 50s) Loss: 0.1119(0.1128) Encoder Grad: 0.4966  Decoder Grad: 0.2183  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][4500/60604] Data 0.000 (0.001) Elapsed 45m 33s (remain 567m 55s) Loss: 0.1041(0.1129) Encoder Grad: 1.0114  Decoder Grad: 0.4702  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][4750/60604] Data 0.000 (0.001) Elapsed 48m 0s (remain 564m 23s) Loss: 0.1052(0.1129) Encoder Grad: 0.4526  Decoder Grad: 0.2093  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][5000/60604] Data 0.000 (0.001) Elapsed 50m 26s (remain 560m 50s) Loss: 0.1143(0.1133) Encoder Grad: 0.4986  Decoder Grad: 0.2174  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][5250/60604] Data 0.000 (0.001) Elapsed 52m 52s (remain 557m 27s) Loss: 0.1506(0.1134) Encoder Grad: 0.6695  Decoder Grad: 0.2841  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][5500/60604] Data 0.000 (0.001) Elapsed 55m 18s (remain 553m 57s) Loss: 0.1114(0.1132) Encoder Grad: 0.4366  Decoder Grad: 0.1932  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][5750/60604] Data 0.000 (0.001) Elapsed 57m 43s (remain 550m 33s) Loss: 0.1176(0.1131) Encoder Grad: 0.6835  Decoder Grad: 0.2915  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][6000/60604] Data 0.000 (0.001) Elapsed 60m 9s (remain 547m 20s) Loss: 0.0976(0.1132) Encoder Grad: 0.4182  Decoder Grad: 0.2225  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][6250/60604] Data 0.000 (0.001) Elapsed 62m 34s (remain 544m 8s) Loss: 0.0948(0.1132) Encoder Grad: 0.3407  Decoder Grad: 0.1633  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][6500/60604] Data 0.000 (0.001) Elapsed 65m 0s (remain 541m 2s) Loss: 0.1381(0.1131) Encoder Grad: 0.4555  Decoder Grad: 0.2183  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][6750/60604] Data 0.000 (0.001) Elapsed 67m 26s (remain 537m 57s) Loss: 0.1381(0.1130) Encoder Grad: 1.1412  Decoder Grad: 0.6479  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][7000/60604] Data 0.000 (0.001) Elapsed 69m 54s (remain 535m 13s) Loss: 0.1058(0.1131) Encoder Grad: 0.4196  Decoder Grad: 0.1825  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][7250/60604] Data 0.000 (0.001) Elapsed 72m 20s (remain 532m 18s) Loss: 0.1166(0.1132) Encoder Grad: 0.8916  Decoder Grad: 0.2200  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][7500/60604] Data 0.000 (0.001) Elapsed 74m 47s (remain 529m 27s) Loss: 0.1157(0.1132) Encoder Grad: 0.5303  Decoder Grad: 0.2096  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][7750/60604] Data 0.000 (0.001) Elapsed 77m 12s (remain 526m 29s) Loss: 0.1488(0.1140) Encoder Grad: 0.5350  Decoder Grad: 0.2340  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][8000/60604] Data 0.000 (0.001) Elapsed 79m 38s (remain 523m 39s) Loss: 0.1140(0.1139) Encoder Grad: 0.3247  Decoder Grad: 0.1610  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][8250/60604] Data 0.000 (0.001) Elapsed 82m 4s (remain 520m 45s) Loss: 0.0998(0.1138) Encoder Grad: 0.3975  Decoder Grad: 0.1967  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][8500/60604] Data 0.000 (0.001) Elapsed 84m 30s (remain 517m 55s) Loss: 0.0959(0.1136) Encoder Grad: 0.4712  Decoder Grad: 0.1959  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][8750/60604] Data 0.000 (0.001) Elapsed 86m 56s (remain 515m 10s) Loss: 0.0923(0.1134) Encoder Grad: 0.4566  Decoder Grad: 0.1740  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][9000/60604] Data 0.000 (0.001) Elapsed 89m 22s (remain 512m 26s) Loss: 0.1062(0.1134) Encoder Grad: 0.4734  Decoder Grad: 0.2127  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][9250/60604] Data 0.000 (0.000) Elapsed 91m 48s (remain 509m 39s) Loss: 0.0885(0.1132) Encoder Grad: 0.4163  Decoder Grad: 0.1719  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][9500/60604] Data 0.000 (0.000) Elapsed 94m 14s (remain 506m 51s) Loss: 0.1414(0.1131) Encoder Grad: 0.5062  Decoder Grad: 0.2005  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][9750/60604] Data 0.000 (0.000) Elapsed 96m 39s (remain 504m 4s) Loss: 0.1209(0.1130) Encoder Grad: 0.5039  Decoder Grad: 0.1906  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][10000/60604] Data 0.000 (0.000) Elapsed 99m 4s (remain 501m 20s) Loss: 0.0961(0.1129) Encoder Grad: 0.5160  Decoder Grad: 0.1847  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][10250/60604] Data 0.000 (0.000) Elapsed 101m 30s (remain 498m 36s) Loss: 0.0923(0.1127) Encoder Grad: 0.3661  Decoder Grad: 0.1564  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][10500/60604] Data 0.000 (0.000) Elapsed 103m 55s (remain 495m 53s) Loss: 0.1268(0.1126) Encoder Grad: 0.5093  Decoder Grad: 0.2314  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][10750/60604] Data 0.000 (0.000) Elapsed 106m 23s (remain 493m 21s) Loss: 0.1350(0.1126) Encoder Grad: 0.7805  Decoder Grad: 0.4298  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][11000/60604] Data 0.000 (0.000) Elapsed 108m 50s (remain 490m 44s) Loss: 0.0922(0.1126) Encoder Grad: 0.7348  Decoder Grad: 0.1777  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][11250/60604] Data 0.000 (0.000) Elapsed 111m 16s (remain 488m 7s) Loss: 0.1410(0.1125) Encoder Grad: 0.4523  Decoder Grad: 0.1804  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][11500/60604] Data 0.000 (0.000) Elapsed 113m 42s (remain 485m 29s) Loss: 0.0966(0.1124) Encoder Grad: 0.5186  Decoder Grad: 0.2292  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][11750/60604] Data 0.000 (0.000) Elapsed 116m 8s (remain 482m 52s) Loss: 0.0991(0.1124) Encoder Grad: 0.3909  Decoder Grad: 0.1825  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][12000/60604] Data 0.000 (0.000) Elapsed 118m 35s (remain 480m 16s) Loss: 0.0926(0.1123) Encoder Grad: 0.4201  Decoder Grad: 0.2033  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][12250/60604] Data 0.000 (0.000) Elapsed 121m 2s (remain 477m 44s) Loss: 0.1012(0.1122) Encoder Grad: 0.4304  Decoder Grad: 0.2314  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][12500/60604] Data 0.000 (0.000) Elapsed 123m 29s (remain 475m 10s) Loss: 0.0674(0.1121) Encoder Grad: 0.4039  Decoder Grad: 0.1974  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][12750/60604] Data 0.000 (0.000) Elapsed 125m 55s (remain 472m 33s) Loss: 0.0785(0.1120) Encoder Grad: 0.3995  Decoder Grad: 0.1897  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][13000/60604] Data 0.000 (0.000) Elapsed 128m 22s (remain 470m 1s) Loss: 0.1044(0.1119) Encoder Grad: 0.4887  Decoder Grad: 0.2142  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][13250/60604] Data 0.000 (0.000) Elapsed 130m 47s (remain 467m 24s) Loss: 0.0875(0.1118) Encoder Grad: 0.9245  Decoder Grad: 0.4041  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][13500/60604] Data 0.000 (0.000) Elapsed 133m 13s (remain 464m 49s) Loss: 0.0683(0.1118) Encoder Grad: 0.3102  Decoder Grad: 0.1310  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][13750/60604] Data 0.000 (0.000) Elapsed 135m 39s (remain 462m 12s) Loss: 0.0788(0.1116) Encoder Grad: 1.0436  Decoder Grad: 0.3442  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][14000/60604] Data 0.000 (0.000) Elapsed 138m 5s (remain 459m 38s) Loss: 0.1361(0.1116) Encoder Grad: 0.5238  Decoder Grad: 0.2051  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][14250/60604] Data 0.000 (0.000) Elapsed 140m 32s (remain 457m 6s) Loss: 0.1152(0.1115) Encoder Grad: 0.3458  Decoder Grad: 0.1949  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][14500/60604] Data 0.000 (0.000) Elapsed 142m 57s (remain 454m 31s) Loss: 0.1210(0.1116) Encoder Grad: 0.3696  Decoder Grad: 0.1813  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][14750/60604] Data 0.000 (0.000) Elapsed 145m 23s (remain 451m 58s) Loss: 0.1293(0.1116) Encoder Grad: 0.5695  Decoder Grad: 0.2395  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][15000/60604] Data 0.000 (0.000) Elapsed 147m 50s (remain 449m 26s) Loss: 0.1240(0.1116) Encoder Grad: 0.6709  Decoder Grad: 0.2520  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][15250/60604] Data 0.000 (0.000) Elapsed 150m 16s (remain 446m 53s) Loss: 0.1016(0.1115) Encoder Grad: 0.4088  Decoder Grad: 0.1896  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][15500/60604] Data 0.000 (0.000) Elapsed 152m 42s (remain 444m 18s) Loss: 0.1063(0.1114) Encoder Grad: 0.5178  Decoder Grad: 0.1769  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][15750/60604] Data 0.000 (0.000) Elapsed 155m 7s (remain 441m 45s) Loss: 0.1193(0.1113) Encoder Grad: 0.4399  Decoder Grad: 0.2187  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][16000/60604] Data 0.000 (0.000) Elapsed 157m 33s (remain 439m 12s) Loss: 0.1337(0.1113) Encoder Grad: 0.3676  Decoder Grad: 0.1687  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][16250/60604] Data 0.000 (0.000) Elapsed 159m 59s (remain 436m 40s) Loss: 0.0974(0.1112) Encoder Grad: 0.4433  Decoder Grad: 0.2230  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][16500/60604] Data 0.000 (0.000) Elapsed 162m 26s (remain 434m 10s) Loss: 0.0893(0.1114) Encoder Grad: 0.3479  Decoder Grad: 0.1546  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][16750/60604] Data 0.000 (0.000) Elapsed 164m 51s (remain 431m 35s) Loss: 0.0771(0.1113) Encoder Grad: 0.4562  Decoder Grad: 0.2351  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][17000/60604] Data 0.000 (0.000) Elapsed 167m 18s (remain 429m 5s) Loss: 0.1068(0.1112) Encoder Grad: 0.4728  Decoder Grad: 0.2408  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][17250/60604] Data 0.000 (0.000) Elapsed 169m 43s (remain 426m 31s) Loss: 0.1041(0.1110) Encoder Grad: 0.7082  Decoder Grad: 0.2115  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][17500/60604] Data 0.000 (0.000) Elapsed 172m 10s (remain 424m 1s) Loss: 0.1298(0.1110) Encoder Grad: 0.7638  Decoder Grad: 0.2525  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][17750/60604] Data 0.000 (0.000) Elapsed 174m 37s (remain 421m 33s) Loss: 0.0995(0.1109) Encoder Grad: 0.5792  Decoder Grad: 0.2062  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][18000/60604] Data 0.000 (0.000) Elapsed 177m 4s (remain 419m 5s) Loss: 0.0773(0.1108) Encoder Grad: 0.4276  Decoder Grad: 0.1534  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][18250/60604] Data 0.000 (0.000) Elapsed 179m 30s (remain 416m 34s) Loss: 0.0752(0.1107) Encoder Grad: 0.5188  Decoder Grad: 0.2170  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][18500/60604] Data 0.000 (0.000) Elapsed 181m 57s (remain 414m 4s) Loss: 0.1007(0.1106) Encoder Grad: 0.7730  Decoder Grad: 0.3866  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][18750/60604] Data 0.000 (0.000) Elapsed 184m 23s (remain 411m 34s) Loss: 0.0966(0.1105) Encoder Grad: 0.4044  Decoder Grad: 0.2212  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][19000/60604] Data 0.000 (0.000) Elapsed 186m 49s (remain 409m 2s) Loss: 0.1038(0.1104) Encoder Grad: 0.5343  Decoder Grad: 0.1854  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][19250/60604] Data 0.000 (0.000) Elapsed 189m 14s (remain 406m 30s) Loss: 0.0963(0.1103) Encoder Grad: 0.6014  Decoder Grad: 0.2573  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][19500/60604] Data 0.000 (0.000) Elapsed 191m 40s (remain 404m 0s) Loss: 0.1271(0.1103) Encoder Grad: 0.4596  Decoder Grad: 0.2282  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][19750/60604] Data 0.000 (0.000) Elapsed 194m 5s (remain 401m 28s) Loss: 0.0822(0.1102) Encoder Grad: 0.5234  Decoder Grad: 0.2003  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][20000/60604] Data 0.000 (0.000) Elapsed 196m 31s (remain 398m 58s) Loss: 0.1089(0.1102) Encoder Grad: 0.5044  Decoder Grad: 0.2210  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][20250/60604] Data 0.000 (0.000) Elapsed 198m 57s (remain 396m 27s) Loss: 0.1051(0.1101) Encoder Grad: 0.5511  Decoder Grad: 0.1950  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][20500/60604] Data 0.000 (0.000) Elapsed 201m 24s (remain 393m 58s) Loss: 0.1233(0.1100) Encoder Grad: 0.4690  Decoder Grad: 0.2227  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][20750/60604] Data 0.000 (0.000) Elapsed 203m 50s (remain 391m 28s) Loss: 0.1205(0.1099) Encoder Grad: 0.6913  Decoder Grad: 0.1877  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][21000/60604] Data 0.000 (0.000) Elapsed 206m 17s (remain 389m 0s) Loss: 0.1343(0.1099) Encoder Grad: 0.4676  Decoder Grad: 0.2275  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][21250/60604] Data 0.000 (0.000) Elapsed 208m 42s (remain 386m 29s) Loss: 0.1086(0.1099) Encoder Grad: 0.5659  Decoder Grad: 0.2154  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][21500/60604] Data 0.000 (0.000) Elapsed 211m 8s (remain 383m 59s) Loss: 0.0813(0.1098) Encoder Grad: 1.8739  Decoder Grad: 0.2324  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][21750/60604] Data 0.000 (0.000) Elapsed 213m 32s (remain 381m 27s) Loss: 0.1399(0.1097) Encoder Grad: 0.5205  Decoder Grad: 0.1962  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][22000/60604] Data 0.000 (0.000) Elapsed 215m 59s (remain 378m 58s) Loss: 0.0851(0.1097) Encoder Grad: 0.8042  Decoder Grad: 0.1801  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][22250/60604] Data 0.000 (0.000) Elapsed 218m 25s (remain 376m 29s) Loss: 0.0877(0.1095) Encoder Grad: 0.5317  Decoder Grad: 0.1853  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][22500/60604] Data 0.000 (0.000) Elapsed 220m 52s (remain 374m 1s) Loss: 0.1097(0.1095) Encoder Grad: 0.5005  Decoder Grad: 0.2864  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][22750/60604] Data 0.000 (0.000) Elapsed 223m 17s (remain 371m 31s) Loss: 0.0869(0.1095) Encoder Grad: 0.3964  Decoder Grad: 0.1665  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][23000/60604] Data 0.000 (0.000) Elapsed 225m 43s (remain 369m 0s) Loss: 0.0843(0.1094) Encoder Grad: 0.3433  Decoder Grad: 0.1673  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][23250/60604] Data 0.000 (0.000) Elapsed 228m 9s (remain 366m 32s) Loss: 0.0768(0.1093) Encoder Grad: 0.3860  Decoder Grad: 0.1681  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][23500/60604] Data 0.000 (0.000) Elapsed 230m 35s (remain 364m 3s) Loss: 0.1005(0.1093) Encoder Grad: 0.3459  Decoder Grad: 0.1588  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][23750/60604] Data 0.000 (0.000) Elapsed 233m 0s (remain 361m 33s) Loss: 0.1345(0.1092) Encoder Grad: 0.4956  Decoder Grad: 0.1832  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][24000/60604] Data 0.000 (0.000) Elapsed 235m 26s (remain 359m 3s) Loss: 0.0984(0.1091) Encoder Grad: 0.5110  Decoder Grad: 0.2321  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][24250/60604] Data 0.000 (0.000) Elapsed 237m 51s (remain 356m 32s) Loss: 0.0741(0.1090) Encoder Grad: 0.3955  Decoder Grad: 0.1743  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][24500/60604] Data 0.000 (0.000) Elapsed 240m 16s (remain 354m 3s) Loss: 0.1645(0.1089) Encoder Grad: 0.4423  Decoder Grad: 0.2118  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][24750/60604] Data 0.000 (0.000) Elapsed 242m 42s (remain 351m 34s) Loss: 0.1220(0.1089) Encoder Grad: 0.6638  Decoder Grad: 0.2366  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][25000/60604] Data 0.000 (0.000) Elapsed 245m 8s (remain 349m 6s) Loss: 0.1085(0.1089) Encoder Grad: 0.8265  Decoder Grad: 0.2095  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][25250/60604] Data 0.000 (0.000) Elapsed 247m 33s (remain 346m 35s) Loss: 0.1300(0.1088) Encoder Grad: 0.4642  Decoder Grad: 0.2340  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][25500/60604] Data 0.000 (0.000) Elapsed 250m 0s (remain 344m 8s) Loss: 0.0715(0.1088) Encoder Grad: 0.3680  Decoder Grad: 0.1578  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][25750/60604] Data 0.000 (0.000) Elapsed 252m 25s (remain 341m 39s) Loss: 0.0716(0.1087) Encoder Grad: 0.3740  Decoder Grad: 0.1875  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][26000/60604] Data 0.000 (0.000) Elapsed 254m 52s (remain 339m 11s) Loss: 0.0892(0.1087) Encoder Grad: 0.4185  Decoder Grad: 0.1696  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][26250/60604] Data 0.000 (0.000) Elapsed 257m 19s (remain 336m 44s) Loss: 0.1002(0.1086) Encoder Grad: 0.4536  Decoder Grad: 0.2051  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][26500/60604] Data 0.000 (0.000) Elapsed 259m 45s (remain 334m 15s) Loss: 0.0774(0.1086) Encoder Grad: 0.6832  Decoder Grad: 0.2915  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][26750/60604] Data 0.000 (0.000) Elapsed 262m 9s (remain 331m 45s) Loss: 0.0795(0.1085) Encoder Grad: 0.4151  Decoder Grad: 0.1545  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][27000/60604] Data 0.000 (0.000) Elapsed 264m 36s (remain 329m 18s) Loss: 0.1240(0.1086) Encoder Grad: 0.5755  Decoder Grad: 0.2561  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][27250/60604] Data 0.000 (0.000) Elapsed 267m 1s (remain 326m 48s) Loss: 0.1164(0.1085) Encoder Grad: 0.4083  Decoder Grad: 0.1792  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][27500/60604] Data 0.000 (0.000) Elapsed 269m 27s (remain 324m 20s) Loss: 0.1351(0.1085) Encoder Grad: 0.7234  Decoder Grad: 0.2721  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][27750/60604] Data 0.000 (0.000) Elapsed 271m 54s (remain 321m 53s) Loss: 0.0955(0.1084) Encoder Grad: 0.4930  Decoder Grad: 0.1841  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][28000/60604] Data 0.000 (0.000) Elapsed 274m 20s (remain 319m 25s) Loss: 0.1029(0.1083) Encoder Grad: 0.3921  Decoder Grad: 0.1953  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][28250/60604] Data 0.000 (0.000) Elapsed 276m 46s (remain 316m 57s) Loss: 0.0927(0.1082) Encoder Grad: 0.3627  Decoder Grad: 0.1705  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][28500/60604] Data 0.000 (0.000) Elapsed 279m 11s (remain 314m 28s) Loss: 0.0982(0.1081) Encoder Grad: 0.5346  Decoder Grad: 0.2166  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][28750/60604] Data 0.000 (0.000) Elapsed 281m 36s (remain 311m 59s) Loss: 0.1354(0.1080) Encoder Grad: 0.5165  Decoder Grad: 0.1567  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][29000/60604] Data 0.000 (0.000) Elapsed 284m 2s (remain 309m 31s) Loss: 0.0751(0.1079) Encoder Grad: 0.3567  Decoder Grad: 0.1458  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][29250/60604] Data 0.000 (0.000) Elapsed 286m 27s (remain 307m 2s) Loss: 0.1082(0.1079) Encoder Grad: 1.1061  Decoder Grad: 0.1641  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][29500/60604] Data 0.000 (0.000) Elapsed 288m 52s (remain 304m 33s) Loss: 0.1016(0.1078) Encoder Grad: 0.3230  Decoder Grad: 0.1651  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][29750/60604] Data 0.000 (0.000) Elapsed 291m 19s (remain 302m 6s) Loss: 0.0740(0.1077) Encoder Grad: 0.3577  Decoder Grad: 0.1663  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][30000/60604] Data 0.000 (0.000) Elapsed 293m 45s (remain 299m 38s) Loss: 0.0939(0.1077) Encoder Grad: 0.5210  Decoder Grad: 0.2649  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][30250/60604] Data 0.000 (0.000) Elapsed 296m 10s (remain 297m 10s) Loss: 0.0891(0.1077) Encoder Grad: 0.5968  Decoder Grad: 0.2734  Encoder LR: 0.000051  Decoder LR: 0.000201  \n",
      "Epoch: [3][30500/60604] Data 0.000 (0.000) Elapsed 298m 36s (remain 294m 42s) Loss: 0.0912(0.1076) Encoder Grad: 0.3974  Decoder Grad: 0.1537  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][30750/60604] Data 0.000 (0.000) Elapsed 301m 2s (remain 292m 14s) Loss: 0.0649(0.1074) Encoder Grad: 0.2938  Decoder Grad: 0.1226  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][31000/60604] Data 0.000 (0.000) Elapsed 303m 28s (remain 289m 47s) Loss: 0.1000(0.1072) Encoder Grad: 0.6115  Decoder Grad: 0.2993  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][31250/60604] Data 0.000 (0.000) Elapsed 305m 54s (remain 287m 20s) Loss: 0.0451(0.1070) Encoder Grad: 0.3467  Decoder Grad: 0.1177  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][31500/60604] Data 0.000 (0.000) Elapsed 308m 21s (remain 284m 52s) Loss: 0.0679(0.1068) Encoder Grad: 0.2823  Decoder Grad: 0.1210  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][31750/60604] Data 0.000 (0.000) Elapsed 310m 46s (remain 282m 24s) Loss: 0.0628(0.1066) Encoder Grad: 0.2832  Decoder Grad: 0.1295  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][32000/60604] Data 0.000 (0.000) Elapsed 313m 14s (remain 279m 58s) Loss: 0.1202(0.1064) Encoder Grad: 0.6850  Decoder Grad: 0.1565  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][32250/60604] Data 0.000 (0.000) Elapsed 315m 40s (remain 277m 31s) Loss: 0.0530(0.1062) Encoder Grad: 0.3411  Decoder Grad: 0.1503  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][32500/60604] Data 0.000 (0.000) Elapsed 318m 5s (remain 275m 2s) Loss: 0.0700(0.1059) Encoder Grad: 0.4583  Decoder Grad: 0.1639  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][32750/60604] Data 0.000 (0.000) Elapsed 320m 30s (remain 272m 34s) Loss: 0.0475(0.1057) Encoder Grad: 0.3506  Decoder Grad: 0.1290  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][33000/60604] Data 0.000 (0.000) Elapsed 322m 55s (remain 270m 6s) Loss: 0.0823(0.1055) Encoder Grad: 0.4109  Decoder Grad: 0.1752  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][33250/60604] Data 0.000 (0.000) Elapsed 325m 22s (remain 267m 39s) Loss: 0.0583(0.1053) Encoder Grad: 0.3915  Decoder Grad: 0.1989  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][33500/60604] Data 0.000 (0.000) Elapsed 327m 49s (remain 265m 12s) Loss: 0.0777(0.1051) Encoder Grad: 0.4529  Decoder Grad: 0.1973  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][33750/60604] Data 0.000 (0.000) Elapsed 330m 14s (remain 262m 45s) Loss: 0.0704(0.1049) Encoder Grad: 0.3603  Decoder Grad: 0.1341  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][34000/60604] Data 0.000 (0.000) Elapsed 332m 39s (remain 260m 16s) Loss: 0.0823(0.1046) Encoder Grad: 0.4015  Decoder Grad: 0.1594  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][34250/60604] Data 0.000 (0.000) Elapsed 335m 5s (remain 257m 49s) Loss: 0.0858(0.1044) Encoder Grad: 0.4071  Decoder Grad: 0.1538  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][34500/60604] Data 0.000 (0.000) Elapsed 337m 31s (remain 255m 22s) Loss: 0.1028(0.1042) Encoder Grad: 0.3904  Decoder Grad: 0.1574  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][34750/60604] Data 0.000 (0.000) Elapsed 339m 58s (remain 252m 55s) Loss: 0.0701(0.1040) Encoder Grad: 0.5774  Decoder Grad: 0.2368  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][35000/60604] Data 0.000 (0.000) Elapsed 342m 24s (remain 250m 27s) Loss: 0.0441(0.1038) Encoder Grad: 0.2532  Decoder Grad: 0.1078  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][35250/60604] Data 0.000 (0.000) Elapsed 344m 48s (remain 247m 59s) Loss: 0.0410(0.1036) Encoder Grad: 0.3229  Decoder Grad: 0.1377  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][35500/60604] Data 0.000 (0.000) Elapsed 347m 14s (remain 245m 31s) Loss: 0.0881(0.1034) Encoder Grad: 0.5622  Decoder Grad: 0.1915  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][35750/60604] Data 0.000 (0.000) Elapsed 349m 39s (remain 243m 4s) Loss: 0.0524(0.1032) Encoder Grad: 0.2502  Decoder Grad: 0.1119  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][36000/60604] Data 0.000 (0.000) Elapsed 352m 5s (remain 240m 37s) Loss: 0.0899(0.1030) Encoder Grad: 0.3005  Decoder Grad: 0.1279  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][36250/60604] Data 0.000 (0.000) Elapsed 354m 30s (remain 238m 9s) Loss: 0.0650(0.1028) Encoder Grad: 0.3517  Decoder Grad: 0.1615  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][36500/60604] Data 0.000 (0.000) Elapsed 356m 56s (remain 235m 42s) Loss: 0.0843(0.1026) Encoder Grad: 0.3077  Decoder Grad: 0.1468  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][36750/60604] Data 0.000 (0.000) Elapsed 359m 21s (remain 233m 14s) Loss: 0.0424(0.1024) Encoder Grad: 0.6354  Decoder Grad: 0.0988  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][37000/60604] Data 0.000 (0.000) Elapsed 361m 47s (remain 230m 47s) Loss: 0.1017(0.1023) Encoder Grad: 0.4789  Decoder Grad: 0.2069  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][37250/60604] Data 0.000 (0.000) Elapsed 364m 14s (remain 228m 20s) Loss: 0.0841(0.1021) Encoder Grad: 0.4255  Decoder Grad: 0.1781  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][37500/60604] Data 0.000 (0.000) Elapsed 366m 40s (remain 225m 53s) Loss: 0.0908(0.1019) Encoder Grad: 0.3414  Decoder Grad: 0.1458  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][37750/60604] Data 0.000 (0.000) Elapsed 369m 5s (remain 223m 26s) Loss: 0.0911(0.1017) Encoder Grad: 0.3063  Decoder Grad: 0.1439  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][38000/60604] Data 0.000 (0.000) Elapsed 371m 31s (remain 220m 58s) Loss: 0.0950(0.1015) Encoder Grad: 0.3126  Decoder Grad: 0.1318  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][38250/60604] Data 0.000 (0.000) Elapsed 373m 55s (remain 218m 31s) Loss: 0.0772(0.1013) Encoder Grad: 0.4229  Decoder Grad: 0.1622  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][38500/60604] Data 0.000 (0.000) Elapsed 376m 23s (remain 216m 4s) Loss: 0.0879(0.1011) Encoder Grad: 0.3230  Decoder Grad: 0.1608  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][38750/60604] Data 0.000 (0.000) Elapsed 378m 49s (remain 213m 38s) Loss: 0.0857(0.1010) Encoder Grad: 0.4906  Decoder Grad: 0.1625  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][39000/60604] Data 0.000 (0.000) Elapsed 381m 16s (remain 211m 11s) Loss: 0.0469(0.1008) Encoder Grad: 0.3229  Decoder Grad: 0.1263  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][39250/60604] Data 0.000 (0.000) Elapsed 383m 42s (remain 208m 44s) Loss: 0.0622(0.1006) Encoder Grad: 0.2715  Decoder Grad: 0.1283  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][39500/60604] Data 0.000 (0.000) Elapsed 386m 7s (remain 206m 17s) Loss: 0.0773(0.1004) Encoder Grad: 0.4049  Decoder Grad: 0.1431  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][39750/60604] Data 0.000 (0.000) Elapsed 388m 34s (remain 203m 50s) Loss: 0.0680(0.1002) Encoder Grad: 0.5653  Decoder Grad: 0.1226  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][40000/60604] Data 0.000 (0.000) Elapsed 390m 59s (remain 201m 23s) Loss: 0.0903(0.1001) Encoder Grad: 1.4870  Decoder Grad: 0.6773  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][40250/60604] Data 0.000 (0.000) Elapsed 393m 25s (remain 198m 56s) Loss: 0.0504(0.0999) Encoder Grad: 0.3209  Decoder Grad: 0.1463  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][40500/60604] Data 0.000 (0.000) Elapsed 395m 51s (remain 196m 29s) Loss: 0.0564(0.0997) Encoder Grad: 0.3467  Decoder Grad: 0.1394  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][40750/60604] Data 0.000 (0.000) Elapsed 398m 16s (remain 194m 1s) Loss: 0.0982(0.0995) Encoder Grad: 0.3145  Decoder Grad: 0.1438  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][41000/60604] Data 0.000 (0.000) Elapsed 400m 41s (remain 191m 34s) Loss: 0.0641(0.0993) Encoder Grad: 0.4034  Decoder Grad: 0.1511  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][41250/60604] Data 0.000 (0.000) Elapsed 403m 6s (remain 189m 7s) Loss: 0.0544(0.0992) Encoder Grad: 0.3695  Decoder Grad: 0.1546  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][41500/60604] Data 0.000 (0.000) Elapsed 405m 33s (remain 186m 40s) Loss: 0.0598(0.0990) Encoder Grad: 0.2905  Decoder Grad: 0.1518  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][41750/60604] Data 0.000 (0.000) Elapsed 407m 58s (remain 184m 13s) Loss: 0.0756(0.0988) Encoder Grad: 0.3779  Decoder Grad: 0.1472  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][42000/60604] Data 0.000 (0.000) Elapsed 410m 24s (remain 181m 46s) Loss: 0.0636(0.0987) Encoder Grad: 0.3379  Decoder Grad: 0.1333  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][42250/60604] Data 0.000 (0.000) Elapsed 412m 49s (remain 179m 19s) Loss: 0.0555(0.0985) Encoder Grad: 0.3379  Decoder Grad: 0.1510  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][42500/60604] Data 0.000 (0.000) Elapsed 415m 15s (remain 176m 52s) Loss: 0.0675(0.0983) Encoder Grad: 0.2998  Decoder Grad: 0.1393  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][42750/60604] Data 0.000 (0.000) Elapsed 417m 41s (remain 174m 25s) Loss: 0.0590(0.0982) Encoder Grad: 0.3825  Decoder Grad: 0.1297  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][43000/60604] Data 0.000 (0.000) Elapsed 420m 7s (remain 171m 58s) Loss: 0.0520(0.0980) Encoder Grad: 0.3338  Decoder Grad: 0.1218  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][43250/60604] Data 0.000 (0.000) Elapsed 422m 33s (remain 169m 32s) Loss: 0.0921(0.0979) Encoder Grad: 0.3356  Decoder Grad: 0.1445  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][43500/60604] Data 0.000 (0.000) Elapsed 424m 58s (remain 167m 4s) Loss: 0.1012(0.0977) Encoder Grad: 0.3907  Decoder Grad: 0.1741  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][43750/60604] Data 0.000 (0.000) Elapsed 427m 24s (remain 164m 38s) Loss: 0.0774(0.0975) Encoder Grad: 0.3501  Decoder Grad: 0.1400  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][44000/60604] Data 0.000 (0.000) Elapsed 429m 50s (remain 162m 11s) Loss: 0.0717(0.0974) Encoder Grad: 0.4585  Decoder Grad: 0.1799  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][44250/60604] Data 0.000 (0.000) Elapsed 432m 16s (remain 159m 44s) Loss: 0.0440(0.0972) Encoder Grad: 0.4022  Decoder Grad: 0.1564  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][44500/60604] Data 0.000 (0.000) Elapsed 434m 42s (remain 157m 18s) Loss: 0.0515(0.0971) Encoder Grad: 0.3353  Decoder Grad: 0.1290  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][44750/60604] Data 0.000 (0.000) Elapsed 437m 8s (remain 154m 51s) Loss: 0.0541(0.0969) Encoder Grad: 0.3118  Decoder Grad: 0.1657  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][45000/60604] Data 0.000 (0.000) Elapsed 439m 34s (remain 152m 24s) Loss: 0.0582(0.0968) Encoder Grad: 0.4610  Decoder Grad: 0.1404  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][45250/60604] Data 0.000 (0.000) Elapsed 442m 0s (remain 149m 58s) Loss: 0.0677(0.0966) Encoder Grad: 0.4385  Decoder Grad: 0.1664  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][45500/60604] Data 0.000 (0.000) Elapsed 444m 26s (remain 147m 31s) Loss: 0.0543(0.0965) Encoder Grad: 0.5993  Decoder Grad: 0.2044  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][45750/60604] Data 0.000 (0.000) Elapsed 446m 52s (remain 145m 4s) Loss: 0.0554(0.0963) Encoder Grad: 0.3771  Decoder Grad: 0.1639  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][46000/60604] Data 0.000 (0.000) Elapsed 449m 18s (remain 142m 37s) Loss: 0.0508(0.0962) Encoder Grad: 0.2341  Decoder Grad: 0.1022  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][46250/60604] Data 0.000 (0.000) Elapsed 451m 44s (remain 140m 11s) Loss: 0.0590(0.0960) Encoder Grad: 0.3602  Decoder Grad: 0.1152  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][46500/60604] Data 0.000 (0.000) Elapsed 454m 10s (remain 137m 44s) Loss: 0.0780(0.0959) Encoder Grad: 0.7230  Decoder Grad: 0.2028  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][46750/60604] Data 0.000 (0.000) Elapsed 456m 37s (remain 135m 18s) Loss: 0.0660(0.0958) Encoder Grad: 0.3507  Decoder Grad: 0.1420  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][47000/60604] Data 0.000 (0.000) Elapsed 459m 3s (remain 132m 51s) Loss: 0.0769(0.0956) Encoder Grad: 0.3472  Decoder Grad: 0.1439  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][47250/60604] Data 0.000 (0.000) Elapsed 461m 29s (remain 130m 25s) Loss: 0.0703(0.0955) Encoder Grad: 0.3375  Decoder Grad: 0.1356  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][47500/60604] Data 0.000 (0.000) Elapsed 463m 55s (remain 127m 58s) Loss: 0.0584(0.0953) Encoder Grad: 0.3430  Decoder Grad: 0.1427  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][47750/60604] Data 0.000 (0.000) Elapsed 466m 21s (remain 125m 31s) Loss: 0.0760(0.0952) Encoder Grad: 0.3417  Decoder Grad: 0.1416  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][48000/60604] Data 0.000 (0.000) Elapsed 468m 46s (remain 123m 4s) Loss: 0.0683(0.0951) Encoder Grad: 0.4104  Decoder Grad: 0.1767  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][48250/60604] Data 0.000 (0.000) Elapsed 471m 11s (remain 120m 37s) Loss: 0.1074(0.0949) Encoder Grad: 0.3587  Decoder Grad: 0.1514  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][48500/60604] Data 0.000 (0.000) Elapsed 473m 36s (remain 118m 11s) Loss: 0.0836(0.0948) Encoder Grad: 0.3830  Decoder Grad: 0.1543  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][48750/60604] Data 0.000 (0.000) Elapsed 476m 3s (remain 115m 44s) Loss: 0.0664(0.0947) Encoder Grad: 0.3540  Decoder Grad: 0.1308  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][49000/60604] Data 0.000 (0.000) Elapsed 478m 29s (remain 113m 18s) Loss: 0.0687(0.0945) Encoder Grad: 0.3128  Decoder Grad: 0.1497  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][49250/60604] Data 0.000 (0.000) Elapsed 480m 55s (remain 110m 51s) Loss: 0.0927(0.0944) Encoder Grad: 0.3658  Decoder Grad: 0.1559  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][49500/60604] Data 0.000 (0.000) Elapsed 483m 21s (remain 108m 25s) Loss: 0.0518(0.0942) Encoder Grad: 0.3211  Decoder Grad: 0.1516  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][49750/60604] Data 0.000 (0.000) Elapsed 485m 47s (remain 105m 58s) Loss: 0.0439(0.0941) Encoder Grad: 0.5094  Decoder Grad: 0.1323  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][50000/60604] Data 0.000 (0.000) Elapsed 488m 14s (remain 103m 32s) Loss: 0.0753(0.0940) Encoder Grad: 0.4169  Decoder Grad: 0.1681  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][50250/60604] Data 0.000 (0.000) Elapsed 490m 40s (remain 101m 5s) Loss: 0.0948(0.0938) Encoder Grad: 0.4684  Decoder Grad: 0.1758  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][50500/60604] Data 0.000 (0.000) Elapsed 493m 5s (remain 98m 38s) Loss: 0.0838(0.0937) Encoder Grad: 0.3287  Decoder Grad: 0.1613  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][50750/60604] Data 0.000 (0.000) Elapsed 495m 31s (remain 96m 12s) Loss: 0.0340(0.0936) Encoder Grad: 0.2481  Decoder Grad: 0.0916  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][51000/60604] Data 0.000 (0.000) Elapsed 497m 56s (remain 93m 45s) Loss: 0.0757(0.0935) Encoder Grad: 0.3413  Decoder Grad: 0.1553  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][51250/60604] Data 0.000 (0.000) Elapsed 500m 22s (remain 91m 18s) Loss: 0.0526(0.0933) Encoder Grad: 0.3009  Decoder Grad: 0.1182  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][51500/60604] Data 0.000 (0.000) Elapsed 502m 48s (remain 88m 52s) Loss: 0.0697(0.0932) Encoder Grad: 0.3458  Decoder Grad: 0.1460  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][51750/60604] Data 0.000 (0.000) Elapsed 505m 14s (remain 86m 25s) Loss: 0.0392(0.0931) Encoder Grad: 0.3403  Decoder Grad: 0.1266  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][52000/60604] Data 0.000 (0.000) Elapsed 507m 40s (remain 83m 59s) Loss: 0.1337(0.0930) Encoder Grad: 0.9114  Decoder Grad: 0.1973  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][52250/60604] Data 0.000 (0.000) Elapsed 510m 6s (remain 81m 32s) Loss: 0.0579(0.0929) Encoder Grad: 0.2775  Decoder Grad: 0.1409  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][52500/60604] Data 0.000 (0.000) Elapsed 512m 30s (remain 79m 6s) Loss: 0.0926(0.0927) Encoder Grad: 0.3832  Decoder Grad: 0.1525  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][52750/60604] Data 0.000 (0.000) Elapsed 514m 56s (remain 76m 39s) Loss: 0.0603(0.0926) Encoder Grad: 0.3563  Decoder Grad: 0.1453  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][53000/60604] Data 0.000 (0.000) Elapsed 517m 22s (remain 74m 12s) Loss: 0.0618(0.0925) Encoder Grad: 0.4286  Decoder Grad: 0.1479  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][53250/60604] Data 0.000 (0.000) Elapsed 519m 47s (remain 71m 46s) Loss: 0.0596(0.0924) Encoder Grad: 0.3547  Decoder Grad: 0.1576  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][53500/60604] Data 0.000 (0.000) Elapsed 522m 13s (remain 69m 19s) Loss: 0.0694(0.0923) Encoder Grad: 0.4415  Decoder Grad: 0.1618  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][53750/60604] Data 0.000 (0.000) Elapsed 524m 41s (remain 66m 53s) Loss: 0.0735(0.0922) Encoder Grad: 0.4547  Decoder Grad: 0.1241  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][54000/60604] Data 0.000 (0.000) Elapsed 527m 7s (remain 64m 27s) Loss: 0.0829(0.0920) Encoder Grad: 0.4041  Decoder Grad: 0.1774  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][54250/60604] Data 0.000 (0.000) Elapsed 529m 33s (remain 62m 0s) Loss: 0.1023(0.0919) Encoder Grad: 0.4919  Decoder Grad: 0.1774  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][54500/60604] Data 0.000 (0.000) Elapsed 531m 59s (remain 59m 34s) Loss: 0.0574(0.0918) Encoder Grad: 0.7350  Decoder Grad: 0.2692  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][54750/60604] Data 0.000 (0.000) Elapsed 534m 25s (remain 57m 7s) Loss: 0.0592(0.0917) Encoder Grad: 0.2713  Decoder Grad: 0.1218  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][55000/60604] Data 0.000 (0.000) Elapsed 536m 52s (remain 54m 41s) Loss: 0.0693(0.0916) Encoder Grad: 0.2857  Decoder Grad: 0.1513  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][55250/60604] Data 0.000 (0.000) Elapsed 539m 18s (remain 52m 15s) Loss: 0.1038(0.0915) Encoder Grad: 0.4020  Decoder Grad: 0.2100  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][55500/60604] Data 0.000 (0.000) Elapsed 541m 45s (remain 49m 48s) Loss: 0.0829(0.0914) Encoder Grad: 0.4381  Decoder Grad: 0.1547  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][55750/60604] Data 0.000 (0.000) Elapsed 544m 10s (remain 47m 22s) Loss: 0.0593(0.0912) Encoder Grad: 0.3696  Decoder Grad: 0.1383  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][56000/60604] Data 0.000 (0.000) Elapsed 546m 36s (remain 44m 55s) Loss: 0.0969(0.0911) Encoder Grad: 0.5068  Decoder Grad: 0.2255  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][56250/60604] Data 0.000 (0.000) Elapsed 549m 2s (remain 42m 29s) Loss: 0.0854(0.0910) Encoder Grad: 0.4786  Decoder Grad: 0.1689  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][56500/60604] Data 0.000 (0.000) Elapsed 551m 28s (remain 40m 2s) Loss: 0.0634(0.0909) Encoder Grad: 0.4370  Decoder Grad: 0.1623  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][56750/60604] Data 0.000 (0.000) Elapsed 553m 53s (remain 37m 36s) Loss: 0.0870(0.0908) Encoder Grad: 0.4150  Decoder Grad: 0.1926  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][57000/60604] Data 0.000 (0.000) Elapsed 556m 19s (remain 35m 9s) Loss: 0.0735(0.0907) Encoder Grad: 0.5636  Decoder Grad: 0.2407  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][57250/60604] Data 0.000 (0.000) Elapsed 558m 44s (remain 32m 43s) Loss: 0.0542(0.0906) Encoder Grad: 0.3071  Decoder Grad: 0.1408  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][57500/60604] Data 0.000 (0.000) Elapsed 561m 10s (remain 30m 16s) Loss: 0.0639(0.0905) Encoder Grad: 0.3570  Decoder Grad: 0.1467  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][57750/60604] Data 0.000 (0.000) Elapsed 563m 34s (remain 27m 50s) Loss: 0.0690(0.0904) Encoder Grad: 0.3936  Decoder Grad: 0.2124  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][58000/60604] Data 0.000 (0.000) Elapsed 566m 0s (remain 25m 24s) Loss: 0.0739(0.0903) Encoder Grad: 0.3673  Decoder Grad: 0.1535  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][58250/60604] Data 0.000 (0.000) Elapsed 568m 26s (remain 22m 57s) Loss: 0.0520(0.0902) Encoder Grad: 0.4733  Decoder Grad: 0.1544  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][58500/60604] Data 0.000 (0.000) Elapsed 570m 53s (remain 20m 31s) Loss: 0.0948(0.0901) Encoder Grad: 0.3904  Decoder Grad: 0.1909  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][58750/60604] Data 0.000 (0.000) Elapsed 573m 20s (remain 18m 4s) Loss: 0.0473(0.0900) Encoder Grad: 0.3596  Decoder Grad: 0.1300  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][59000/60604] Data 0.000 (0.000) Elapsed 575m 46s (remain 15m 38s) Loss: 0.0684(0.0899) Encoder Grad: 0.3349  Decoder Grad: 0.1709  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][59250/60604] Data 0.000 (0.000) Elapsed 578m 12s (remain 13m 12s) Loss: 0.0569(0.0898) Encoder Grad: 0.3592  Decoder Grad: 0.1360  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][59500/60604] Data 0.000 (0.000) Elapsed 580m 38s (remain 10m 45s) Loss: 0.0825(0.0897) Encoder Grad: 0.4190  Decoder Grad: 0.1837  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][59750/60604] Data 0.000 (0.000) Elapsed 583m 4s (remain 8m 19s) Loss: 0.0784(0.0896) Encoder Grad: 0.3845  Decoder Grad: 0.1606  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][60000/60604] Data 0.000 (0.000) Elapsed 585m 30s (remain 5m 53s) Loss: 0.0639(0.0895) Encoder Grad: 0.3441  Decoder Grad: 0.1368  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][60250/60604] Data 0.000 (0.000) Elapsed 587m 56s (remain 3m 26s) Loss: 0.0647(0.0894) Encoder Grad: 0.5233  Decoder Grad: 0.2981  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][60500/60604] Data 0.000 (0.000) Elapsed 590m 23s (remain 1m 0s) Loss: 0.0689(0.0893) Encoder Grad: 0.3113  Decoder Grad: 0.1530  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "Epoch: [3][60603/60604] Data 0.000 (0.000) Elapsed 591m 22s (remain 0m 0s) Loss: 0.0397(0.0892) Encoder Grad: 0.2876  Decoder Grad: 0.1342  Encoder LR: 0.000008  Decoder LR: 0.000030  \n",
      "EVAL: [0/15152] Data 2.417 (2.417) Elapsed 0m 3s (remain 782m 27s) \n",
      "EVAL: [250/15152] Data 0.000 (0.010) Elapsed 0m 48s (remain 47m 48s) \n",
      "EVAL: [500/15152] Data 0.000 (0.005) Elapsed 1m 32s (remain 45m 19s) \n",
      "EVAL: [750/15152] Data 0.000 (0.004) Elapsed 2m 18s (remain 44m 11s) \n",
      "EVAL: [1000/15152] Data 0.000 (0.003) Elapsed 3m 3s (remain 43m 8s) \n",
      "EVAL: [1250/15152] Data 0.000 (0.003) Elapsed 3m 47s (remain 42m 11s) \n",
      "EVAL: [1500/15152] Data 0.000 (0.002) Elapsed 4m 32s (remain 41m 18s) \n",
      "EVAL: [1750/15152] Data 0.000 (0.002) Elapsed 5m 17s (remain 40m 33s) \n",
      "EVAL: [2000/15152] Data 0.000 (0.002) Elapsed 6m 3s (remain 39m 47s) \n",
      "EVAL: [2250/15152] Data 0.000 (0.002) Elapsed 6m 48s (remain 39m 0s) \n",
      "EVAL: [2500/15152] Data 0.000 (0.002) Elapsed 7m 33s (remain 38m 13s) \n",
      "EVAL: [2750/15152] Data 0.000 (0.001) Elapsed 8m 18s (remain 37m 26s) \n",
      "EVAL: [3000/15152] Data 0.000 (0.001) Elapsed 9m 3s (remain 36m 39s) \n",
      "EVAL: [3250/15152] Data 0.000 (0.001) Elapsed 9m 48s (remain 35m 55s) \n",
      "EVAL: [3500/15152] Data 0.000 (0.001) Elapsed 10m 34s (remain 35m 10s) \n",
      "EVAL: [3750/15152] Data 0.000 (0.001) Elapsed 11m 19s (remain 34m 24s) \n",
      "EVAL: [4000/15152] Data 0.000 (0.001) Elapsed 12m 4s (remain 33m 39s) \n",
      "EVAL: [4250/15152] Data 0.000 (0.001) Elapsed 12m 49s (remain 32m 52s) \n",
      "EVAL: [4500/15152] Data 0.000 (0.001) Elapsed 13m 34s (remain 32m 6s) \n",
      "EVAL: [4750/15152] Data 0.000 (0.001) Elapsed 14m 19s (remain 31m 22s) \n",
      "EVAL: [5000/15152] Data 0.000 (0.001) Elapsed 15m 4s (remain 30m 36s) \n",
      "EVAL: [5250/15152] Data 0.000 (0.001) Elapsed 15m 49s (remain 29m 49s) \n",
      "EVAL: [5500/15152] Data 0.000 (0.001) Elapsed 16m 33s (remain 29m 3s) \n",
      "EVAL: [5750/15152] Data 0.000 (0.001) Elapsed 17m 19s (remain 28m 18s) \n",
      "EVAL: [6000/15152] Data 0.000 (0.001) Elapsed 18m 4s (remain 27m 34s) \n",
      "EVAL: [6250/15152] Data 0.007 (0.001) Elapsed 18m 49s (remain 26m 49s) \n",
      "EVAL: [6500/15152] Data 0.000 (0.001) Elapsed 19m 35s (remain 26m 3s) \n",
      "EVAL: [6750/15152] Data 0.000 (0.001) Elapsed 20m 20s (remain 25m 18s) \n",
      "EVAL: [7000/15152] Data 0.005 (0.001) Elapsed 21m 5s (remain 24m 33s) \n",
      "EVAL: [7250/15152] Data 0.000 (0.001) Elapsed 21m 49s (remain 23m 47s) \n",
      "EVAL: [7500/15152] Data 0.000 (0.001) Elapsed 22m 34s (remain 23m 2s) \n",
      "EVAL: [7750/15152] Data 0.005 (0.001) Elapsed 23m 19s (remain 22m 16s) \n",
      "EVAL: [8000/15152] Data 0.000 (0.001) Elapsed 24m 4s (remain 21m 31s) \n",
      "EVAL: [8250/15152] Data 0.000 (0.001) Elapsed 24m 49s (remain 20m 45s) \n",
      "EVAL: [8500/15152] Data 0.000 (0.001) Elapsed 25m 34s (remain 20m 0s) \n",
      "EVAL: [8750/15152] Data 0.000 (0.001) Elapsed 26m 18s (remain 19m 14s) \n",
      "EVAL: [9000/15152] Data 0.000 (0.001) Elapsed 27m 2s (remain 18m 29s) \n",
      "EVAL: [9250/15152] Data 0.000 (0.001) Elapsed 27m 48s (remain 17m 44s) \n",
      "EVAL: [9500/15152] Data 0.000 (0.001) Elapsed 28m 33s (remain 16m 59s) \n",
      "EVAL: [9750/15152] Data 0.000 (0.001) Elapsed 29m 18s (remain 16m 13s) \n",
      "EVAL: [10000/15152] Data 0.000 (0.001) Elapsed 30m 3s (remain 15m 28s) \n",
      "EVAL: [10250/15152] Data 0.000 (0.001) Elapsed 30m 47s (remain 14m 43s) \n",
      "EVAL: [10500/15152] Data 0.000 (0.001) Elapsed 31m 32s (remain 13m 58s) \n",
      "EVAL: [10750/15152] Data 0.000 (0.001) Elapsed 32m 16s (remain 13m 12s) \n",
      "EVAL: [11000/15152] Data 0.000 (0.001) Elapsed 33m 1s (remain 12m 27s) \n",
      "EVAL: [11250/15152] Data 0.000 (0.001) Elapsed 33m 46s (remain 11m 42s) \n",
      "EVAL: [11500/15152] Data 0.000 (0.001) Elapsed 34m 31s (remain 10m 57s) \n",
      "EVAL: [11750/15152] Data 0.000 (0.001) Elapsed 35m 16s (remain 10m 12s) \n",
      "EVAL: [12000/15152] Data 0.000 (0.001) Elapsed 36m 1s (remain 9m 27s) \n",
      "EVAL: [12250/15152] Data 0.000 (0.001) Elapsed 36m 45s (remain 8m 42s) \n",
      "EVAL: [12500/15152] Data 0.000 (0.001) Elapsed 37m 31s (remain 7m 57s) \n",
      "EVAL: [12750/15152] Data 0.000 (0.001) Elapsed 38m 15s (remain 7m 12s) \n",
      "EVAL: [13000/15152] Data 0.000 (0.001) Elapsed 38m 59s (remain 6m 27s) \n",
      "EVAL: [13250/15152] Data 0.000 (0.001) Elapsed 39m 44s (remain 5m 42s) \n",
      "EVAL: [13500/15152] Data 0.000 (0.001) Elapsed 40m 30s (remain 4m 57s) \n",
      "EVAL: [13750/15152] Data 0.000 (0.001) Elapsed 41m 15s (remain 4m 12s) \n",
      "EVAL: [14000/15152] Data 0.000 (0.001) Elapsed 42m 0s (remain 3m 27s) \n",
      "EVAL: [14250/15152] Data 0.000 (0.001) Elapsed 42m 45s (remain 2m 42s) \n",
      "EVAL: [14500/15152] Data 0.000 (0.001) Elapsed 43m 29s (remain 1m 57s) \n",
      "EVAL: [14750/15152] Data 0.000 (0.001) Elapsed 44m 14s (remain 1m 12s) \n",
      "EVAL: [15000/15152] Data 0.000 (0.001) Elapsed 44m 58s (remain 0m 27s) \n",
      "EVAL: [15151/15152] Data 0.000 (0.001) Elapsed 45m 25s (remain 0m 0s) \n",
      "labels: ['InChI=1S/C24H23N5O4/c1-14-13-15(7-8-17(14)28-12-10-20(28)30)27-11-9-16-21(23(25)31)26-29(22(16)24(27)32)18-5-3-4-6-19(18)33-2/h3-8,13H,9-12H2,1-2H3,(H2,25,31)'\n",
      " 'InChI=1S/C17H24N2O4S/c1-12(20)18-13(14-7-6-10-24-14)11-15(21)19-17(16(22)23)8-4-2-3-5-9-17/h6-7,10,13H,2-5,8-9,11H2,1H3,(H,18,20)(H,19,21)(H,22,23)'\n",
      " 'InChI=1S/C10H15N5S/c1-7-6-8(9(11)12)14-10(13-7)15-2-4-16-5-3-15/h6H,2-5H2,1H3,(H3,11,12)'\n",
      " 'InChI=1S/C59H108O6/c1-4-7-10-13-16-19-22-25-28-30-32-34-37-40-43-46-49-52-58(61)64-55-56(54-63-57(60)51-48-45-42-39-36-33-27-24-21-18-15-12-9-6-3)65-59(62)53-50-47-44-41-38-35-31-29-26-23-20-17-14-11-8-5-2/h16,19,25,28,33,36,56H,4-15,17-18,20-24,26-27,29-32,34-35,37-55H2,1-3H3/b19-16-,28-25-,36-33-'\n",
      " 'InChI=1S/C39H25N5/c1-2-13-30(14-3-1)44-34-18-7-6-17-33(34)41-39(44)29-12-10-11-28(25-29)26-20-22-27(23-21-26)36-38-37(31-15-4-5-16-32(31)40-36)42-35-19-8-9-24-43(35)38/h1-25H']\n",
      "preds: ['InChI=1S/C24H23N5O4/c1-14-13-15(7-8-17(14)27-12-10-20(27)30)27-11-9-16-21(23(25)31)26-29(22(16)24(27)32)18-5-3-4-6-19(18)34-2/h3-8,13H,9-12H2,1-2H3,(H2,25,31)', 'InChI=1S/C17H24N2O4S/c1-12(20)18-13(14-7-6-10-24-14)11-15(21)19-17(16(22)23)8-4-2-3-5-9-17/h6-7,10,13H,2-5,8-9,11H2,1H3,(H,18,20)(H,19,21)(H,22,23)', 'InChI=1S/C10H15N5S/c1-7-6-8(9(11)12)14-10(13-7)15-2-4-16-5-3-15/h6H,2-5H2,1H3,(H3,11,12)', 'InChI=1S/C57H98O6/c1-4-7-10-13-16-19-22-25-27-29-30-31-32-34-36-39-42-45-48-51-57(60)63-54-55(53-60-56(59)50-47-44-41-38-35-22-19-14-11-8-5-2)62-58(61)52-49-46-43-40-37-34-31-28-25-22-20-17-15-12-9-6-3/h16,19,23,25,29,31,54H,4-15,17-18,20-22,24,26-28,30,32-51H2,1-3H3/b19-16-,25-23-,29-27-,33-30-', 'InChI=1S/C39H25N5/c1-2-13-30(14-3-1)43-35-18-7-6-17-33(35)41-39(43)29-12-10-11-27(25-29)26-21-23-28(24-22-26)36-38-37(42-24-9-8-19-36(42)42-36)32-15-4-5-16-33(32)40-36/h1-26H']\n",
      "Epoch 3 - avg_train_loss: 0.0892  time: 38213s\n",
      "Epoch 3 - Score: 6.1775\n",
      "Epoch 3 - Save Best Score: 6.1775 Model\n"
     ]
    }
   ],
   "source": [
    "train_loop(folds, synthetic_folds, CFG.trn_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python385jvsc74a57bd0ce8efb1f28dd4a0568a606b813efaa2aeaaae67617ecb5fd40574a9cea5029cb",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2420.3766,
   "end_time": "2021-04-26T13:34:09.349906",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-04-26T12:53:48.973306",
   "version": "2.3.2"
  },
  "metadata": {
   "interpreter": {
    "hash": "ce8efb1f28dd4a0568a606b813efaa2aeaaae67617ecb5fd40574a9cea5029cb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}